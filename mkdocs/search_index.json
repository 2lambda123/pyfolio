{
    "docs": [
        {
            "location": "/",
            "text": "pyfolio\n\n\n\n\n\n\npyfolio is a Python library for performance and risk analysis of\nfinancial portfolios developed by\n\nQuantopian Inc\n. It works well with the\n\nZipline\n open source backtesting library.\n\n\nAt the core of pyfolio is a so-called tear sheet that consists of\nvarious individual plots that provide a comprehensive image of the\nperformance of a trading algorithm. Here is an example of a tear sheet of a the Zipline algo included as one of our example notebooks:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSee also \nslides of a recent talk about pyfolio.\n\n\nInstallation\n\n\n(Optional) Virtual Environment\n\n\nFor development on pyfolio itself, you might want to use a \nvirtual environment\n to avoid dependency conflicts between \npyfolio\n and other python projects you have. To get set up with a virtual env, run:\n\n\n\nmkvirtualenv pyfolio\n\n\n\n\nbefore running the install commands below.\n\n\nTo install \npyfolio\n via \npip\n issue the following command:\n\n\npip install pyfolio\n\n\n\n\nFor development, clone the git repo and run \npython setup.py develop\n\nand edit the library files directly. Make sure to reload or restart\nthe IPython kernel when you make changes.\n\n\npyfolio\n has the following dependencies:\n - numpy\n - scipy\n - pandas\n - matplotlib\n - \nseaborn\n\n - \npymc3\n (optional)\n - \nzipline\n (optional; requires master, \nnot\n 0.7.0)\n\n\nSome of Pyfolio's functionality, such as the \nBayesian tearsheet\n, requires PyMC3 and Theano. To get set up, you can run:\n\n\npip install theano\n\n\n\n\npip install git+https://github.com/pymc-devs/pymc3\n\n\n\n\nIf you are on OSX and using a non-framework build of python you may need to set your backend:\n\n\necho \"backend: TkAgg\" > ~/.matplotlib/matplotlibrc\n\n\n\n\nUsage\n\n\nA good way to get started is to run the examples in a \nJupyter notebook\n.\n\n\nTo get set up with an example, you can:\n\n\nRun a Jupyter notebook server via:\n\n\njupyter notebook\n\n\n\n\nFrom the notebook list page(usually found at \nhttp://localhost:8888/\n), navigate over to the examples directory, and open any file with a .ipynb extension.\n\n\nExecute the code in a notebook cell by clicking on it and hitting Shift+Enter.\n\n\nQuestions?\n\n\nIf you find a bug, feel free to open an issue on our github tracker.\n\n\nYou can also join our \nmailing list\n.\n\n\nContribute\n\n\nIf you want to contribute, a great place to start would be the \nhelp-wanted issues\n.\n\n\nCredits\n\n\n\n\nGus Gordon (gus@quantopian.com)\n\n\nJustin Lent (justin@quantopian.com)\n\n\nSepideh Sadeghi (sp.sadeghi@gmail.com)\n\n\nThomas Wiecki (thomas@quantopian.com)\n\n\nJessica Stauth (jstauth@quantopian.com)\n\n\nKaren Rubin (karen@quantopian.com)\n\n\nDavid Edwards (dedwards@quantopian.com)\n\n\nAndrew Campbell (andrew@quantopian.com)\n\n\n\n\nFor a full list of contributors, see https://github.com/quantopian/pyfolio/graphs/contributors.",
            "title": "Overview"
        },
        {
            "location": "/#pyfolio",
            "text": "pyfolio is a Python library for performance and risk analysis of\nfinancial portfolios developed by Quantopian Inc . It works well with the Zipline  open source backtesting library.  At the core of pyfolio is a so-called tear sheet that consists of\nvarious individual plots that provide a comprehensive image of the\nperformance of a trading algorithm. Here is an example of a tear sheet of a the Zipline algo included as one of our example notebooks:         See also  slides of a recent talk about pyfolio.",
            "title": "pyfolio"
        },
        {
            "location": "/#installation",
            "text": "",
            "title": "Installation"
        },
        {
            "location": "/#optional-virtual-environment",
            "text": "For development on pyfolio itself, you might want to use a  virtual environment  to avoid dependency conflicts between  pyfolio  and other python projects you have. To get set up with a virtual env, run:  \nmkvirtualenv pyfolio  before running the install commands below.  To install  pyfolio  via  pip  issue the following command:  pip install pyfolio  For development, clone the git repo and run  python setup.py develop \nand edit the library files directly. Make sure to reload or restart\nthe IPython kernel when you make changes.  pyfolio  has the following dependencies:\n - numpy\n - scipy\n - pandas\n - matplotlib\n -  seaborn \n -  pymc3  (optional)\n -  zipline  (optional; requires master,  not  0.7.0)  Some of Pyfolio's functionality, such as the  Bayesian tearsheet , requires PyMC3 and Theano. To get set up, you can run:  pip install theano  pip install git+https://github.com/pymc-devs/pymc3  If you are on OSX and using a non-framework build of python you may need to set your backend:  echo \"backend: TkAgg\" > ~/.matplotlib/matplotlibrc",
            "title": "(Optional) Virtual Environment"
        },
        {
            "location": "/#usage",
            "text": "A good way to get started is to run the examples in a  Jupyter notebook .  To get set up with an example, you can:  Run a Jupyter notebook server via:  jupyter notebook  From the notebook list page(usually found at  http://localhost:8888/ ), navigate over to the examples directory, and open any file with a .ipynb extension.  Execute the code in a notebook cell by clicking on it and hitting Shift+Enter.",
            "title": "Usage"
        },
        {
            "location": "/#questions",
            "text": "If you find a bug, feel free to open an issue on our github tracker.  You can also join our  mailing list .",
            "title": "Questions?"
        },
        {
            "location": "/#contribute",
            "text": "If you want to contribute, a great place to start would be the  help-wanted issues .",
            "title": "Contribute"
        },
        {
            "location": "/#credits",
            "text": "Gus Gordon (gus@quantopian.com)  Justin Lent (justin@quantopian.com)  Sepideh Sadeghi (sp.sadeghi@gmail.com)  Thomas Wiecki (thomas@quantopian.com)  Jessica Stauth (jstauth@quantopian.com)  Karen Rubin (karen@quantopian.com)  David Edwards (dedwards@quantopian.com)  Andrew Campbell (andrew@quantopian.com)   For a full list of contributors, see https://github.com/quantopian/pyfolio/graphs/contributors.",
            "title": "Credits"
        },
        {
            "location": "/whatsnew/",
            "text": "What's New\n\n\nThese are new features and improvements of note in each release.\n\n\nv0.6.0 (Oct, 17, 2016)\n\n\nThis is a major new release from \n0.5.1\n. All users are recommended to upgrade.\n\n\nNew features\n\n\n\n\nComputation of performance and risk measures has been split off into \nempyrical\n. This allows \nZipline\n and \npyfolio\n to use the same code to calculate its risk statistics. By \nAna Ruelas\n and \nAbhi Kalyan\n. \n\n\nNew multistrike cone which redraws the cone when it crossed its initial bounds \nPR310\n. By \nAna Ruelas\n and \nAbhi Kalyan\n.\n\n\n\n\nBugfixes\n\n\n\n\nCan use most recent PyMC3 now.\n\n\nDepends on seaborn 0.7.0 or later now \nPR331\n.\n\n\nDisable buggy computation of round trips per day and per month \nPR339\n.\n\n\n\n\nv0.5.1 (June, 10, 2016)\n\n\nThis is a bugfix release from \n0.5.0\n with limited new functionality. All users are recommended to upgrade.\n\n\nNew features\n\n\n\n\nOOS data is now overlaid on top of box plot \nPR306\n by \nAna Ruelas\n\n\nNew logo \nPR298\n by \nTaso Petridis\n and \nRichard Frank\n\n\nRaw returns plot and cumulative log returns plot \nPR294\n by \nThomas Wiecki\n\n\nNet exposure line to the long/short exposure plot \nPR301\n by \nAna Ruelas\n\n\n\n\nBugfixes\n\n\n\n\nFix drawdown behavior and pandas exception in tear-sheet creation \nPR297\n by \nFlavio Duarte\n\n\n\n\nv0.5.0 (April 21, 2016) -- Olympia\n\n\nThis is a major release from \n0.4.0\n that includes many new analyses and features. We recommend that all users upgrade to this new version. Also update your dependencies, specifically, \npandas>=0.18.0\n, \nseaborn>=0.6.0\n and \nzipline>=0.8.4\n.\n\n\nNew features\n\n\n\n\nNew capacity tear-sheet to assess how much capital can be traded on a strategy \nPR284\n. \nAndrew Campbell\n.\n\n\nBootstrap analysis to assess uncertainty in performance metrics \nPR261\n. \nThomas Wiecki\n\n\nRefactored round-trip analysis to be more general and have better output. Now does full portfolio reconstruction to match trades \nPR293\n. \nThomas Wiecki\n, \nAndrew Campbell\n. See the \ntutorial\n for more information.\n\n\nPrettier printing of tables in notebooks \nPR289\n. \nThomas Wiecki\n\n\nFaster max-drawdown calculation \nPR281\n. \nDevin Stevenson\n\n\nNew metrics tail-ratio and common sense ratio \nPR276\n. \nThomas Wiecki\n\n\nLog-scaled cumulative returns plot and raw returns plot \nPR294\n. \nThomas Wiecki\n\n\n\n\nBug fixes\n\n\n\n\nMany depracation fixes for Pandas 0.18.0, seaborn 0.6.0, and zipline 0.8.4\n\n\n\n\nv0.4.0 (Dec 10, 2015)\n\n\nThis is a major release from 0.3.1 that includes new features and quite a few bug fixes. We recommend that all users upgrade to this new version.\n\n\nNew features\n\n\n\n\nRound-trip analysis \nPR210\n Andrew, Thomas\n\n\nImproved cone to forecast returns that uses a bootstrap instead of linear forecasting \nPR233\n Andrew, Thomas\n\n\nPlot max and median long/short exposures \nPR237\n Andrew\n\n\n\n\nBug fixes\n\n\n\n\nSharpe ratio was calculated incorrectly \nPR219\n Thomas, Justin\n\n\nannual_return() now only computes CAGR in the correct way \nPR234\n Justin\n\n\nCache SPY and Fama-French returns in home-directory instead of install-directory \nPR241\n Joe\n\n\nRemove data files from package \nPR241\n Joe\n\n\nCast factor.name to str \nPR223\n Scotty\n\n\nTest all \ncreate_*_tear_sheet\n functions in all configurations \nPR247\n Thomas\n\n\n\n\nv0.3.1 (Nov 12, 2015)\n\n\nThis is a minor release from 0.3 that includes mostly bugfixes but also some new features. We recommend that all users upgrade to this new version.\n\n\nNew features\n\n\n\n\nAdd Information Ratio \nPR194\n by @MridulS\n\n\nBayesian tear-sheet now accepts 'Fama-French' option to do Bayesian multivariate regression against Fama-French risk factors \nPR200\n by Shane Bussman\n\n\nPlotting of monthly returns \nPR195\n\n\n\n\nBug fixes\n\n\n\n\npos.get_percent_alloc\n was not handling short allocations correctly \nPR201\n\n\nUTC bug with cached Fama-French factors \ncommit\n\n\nSector map was not being passed from \ncreate_returns_tearsheet\n \ncommit\n\n\nNew sector mapping feature was not Python 3 compatible \nPR201\n\n\n\n\nMaintenance\n\n\n\n\nWe now depend on pandas-datareader as the yahoo finance loaders from pandas will be deprecated \nPR181\n by @tswrightsandpointe\n\n\n\n\nContributors\n\n\nBesiders the core developers, we have seen an increase in outside contributions which we greatly appreciate. Specifically, these people contributed to this release:\n\n\n\n\nShane Bussman\n\n\n@MridulS\n\n\n@YihaoLu\n\n\n@jkrauss82\n\n\n@tswrightsandpointe\n\n\n@cgdeboer\n\n\n\n\nv0.3 (Oct 23, 2015)\n\n\nThis is a major release from 0.2 that includes many exciting new features. We recommend that all users upgrade to this new version.\n\n\nNew features\n\n\n\n\nSector exposures: sum positions by sector given a dictionary or series of symbol to sector mappings \nPR166\n\n\nAbility to make cones with multiple shades stdev regions \nPR168\n\n\nSlippage sweep: See how an algorithm performs with various levels of slippage \nPR170\n\n\nStochastic volatility model in Bayesian tear sheet \nPR174\n\n\nAbility to suppress display of position information \nPR177\n\n\n\n\nBug fixes\n\n\n\n\nVarious fixes to make pyfolio pandas 0.17 compatible\n\n\n\n\nv0.2 (Oct 16, 2015)\n\n\nThis is a major release from 0.1 that includes mainly bugfixes and refactorings but also some new features. We recommend that all users upgrade to this new version.\n\n\nNew features\n\n\n\n\nVolatility matched cumulative returns plot \nPR126\n.\n\n\nAllow for different periodicity (annualization factors) in the annual_() methods \nPR164\n.\n\n\nUsers can supply their own interesting periods \nPR163\n.\n\n\nAbility to weight a portfolio of holdings by a metric valued \nPR161\n.\n\n\n\n\nBug fixes\n\n\n\n\nFix drawdown overlaps \nPR150\n.\n\n\nMonthly returns distribution should not stack by year \nPR162\n.\n\n\nFix gross leverage \nPR147",
            "title": "Releases"
        },
        {
            "location": "/whatsnew/#whats-new",
            "text": "These are new features and improvements of note in each release.",
            "title": "What's New"
        },
        {
            "location": "/whatsnew/#v060-oct-17-2016",
            "text": "This is a major new release from  0.5.1 . All users are recommended to upgrade.",
            "title": "v0.6.0 (Oct, 17, 2016)"
        },
        {
            "location": "/whatsnew/#new-features",
            "text": "Computation of performance and risk measures has been split off into  empyrical . This allows  Zipline  and  pyfolio  to use the same code to calculate its risk statistics. By  Ana Ruelas  and  Abhi Kalyan .   New multistrike cone which redraws the cone when it crossed its initial bounds  PR310 . By  Ana Ruelas  and  Abhi Kalyan .",
            "title": "New features"
        },
        {
            "location": "/whatsnew/#bugfixes",
            "text": "Can use most recent PyMC3 now.  Depends on seaborn 0.7.0 or later now  PR331 .  Disable buggy computation of round trips per day and per month  PR339 .",
            "title": "Bugfixes"
        },
        {
            "location": "/whatsnew/#v051-june-10-2016",
            "text": "This is a bugfix release from  0.5.0  with limited new functionality. All users are recommended to upgrade.",
            "title": "v0.5.1 (June, 10, 2016)"
        },
        {
            "location": "/whatsnew/#new-features_1",
            "text": "OOS data is now overlaid on top of box plot  PR306  by  Ana Ruelas  New logo  PR298  by  Taso Petridis  and  Richard Frank  Raw returns plot and cumulative log returns plot  PR294  by  Thomas Wiecki  Net exposure line to the long/short exposure plot  PR301  by  Ana Ruelas",
            "title": "New features"
        },
        {
            "location": "/whatsnew/#bugfixes_1",
            "text": "Fix drawdown behavior and pandas exception in tear-sheet creation  PR297  by  Flavio Duarte",
            "title": "Bugfixes"
        },
        {
            "location": "/whatsnew/#v050-april-21-2016-olympia",
            "text": "This is a major release from  0.4.0  that includes many new analyses and features. We recommend that all users upgrade to this new version. Also update your dependencies, specifically,  pandas>=0.18.0 ,  seaborn>=0.6.0  and  zipline>=0.8.4 .",
            "title": "v0.5.0 (April 21, 2016) -- Olympia"
        },
        {
            "location": "/whatsnew/#new-features_2",
            "text": "New capacity tear-sheet to assess how much capital can be traded on a strategy  PR284 .  Andrew Campbell .  Bootstrap analysis to assess uncertainty in performance metrics  PR261 .  Thomas Wiecki  Refactored round-trip analysis to be more general and have better output. Now does full portfolio reconstruction to match trades  PR293 .  Thomas Wiecki ,  Andrew Campbell . See the  tutorial  for more information.  Prettier printing of tables in notebooks  PR289 .  Thomas Wiecki  Faster max-drawdown calculation  PR281 .  Devin Stevenson  New metrics tail-ratio and common sense ratio  PR276 .  Thomas Wiecki  Log-scaled cumulative returns plot and raw returns plot  PR294 .  Thomas Wiecki",
            "title": "New features"
        },
        {
            "location": "/whatsnew/#bug-fixes",
            "text": "Many depracation fixes for Pandas 0.18.0, seaborn 0.6.0, and zipline 0.8.4",
            "title": "Bug fixes"
        },
        {
            "location": "/whatsnew/#v040-dec-10-2015",
            "text": "This is a major release from 0.3.1 that includes new features and quite a few bug fixes. We recommend that all users upgrade to this new version.",
            "title": "v0.4.0 (Dec 10, 2015)"
        },
        {
            "location": "/whatsnew/#new-features_3",
            "text": "Round-trip analysis  PR210  Andrew, Thomas  Improved cone to forecast returns that uses a bootstrap instead of linear forecasting  PR233  Andrew, Thomas  Plot max and median long/short exposures  PR237  Andrew",
            "title": "New features"
        },
        {
            "location": "/whatsnew/#bug-fixes_1",
            "text": "Sharpe ratio was calculated incorrectly  PR219  Thomas, Justin  annual_return() now only computes CAGR in the correct way  PR234  Justin  Cache SPY and Fama-French returns in home-directory instead of install-directory  PR241  Joe  Remove data files from package  PR241  Joe  Cast factor.name to str  PR223  Scotty  Test all  create_*_tear_sheet  functions in all configurations  PR247  Thomas",
            "title": "Bug fixes"
        },
        {
            "location": "/whatsnew/#v031-nov-12-2015",
            "text": "This is a minor release from 0.3 that includes mostly bugfixes but also some new features. We recommend that all users upgrade to this new version.",
            "title": "v0.3.1 (Nov 12, 2015)"
        },
        {
            "location": "/whatsnew/#new-features_4",
            "text": "Add Information Ratio  PR194  by @MridulS  Bayesian tear-sheet now accepts 'Fama-French' option to do Bayesian multivariate regression against Fama-French risk factors  PR200  by Shane Bussman  Plotting of monthly returns  PR195",
            "title": "New features"
        },
        {
            "location": "/whatsnew/#bug-fixes_2",
            "text": "pos.get_percent_alloc  was not handling short allocations correctly  PR201  UTC bug with cached Fama-French factors  commit  Sector map was not being passed from  create_returns_tearsheet   commit  New sector mapping feature was not Python 3 compatible  PR201",
            "title": "Bug fixes"
        },
        {
            "location": "/whatsnew/#maintenance",
            "text": "We now depend on pandas-datareader as the yahoo finance loaders from pandas will be deprecated  PR181  by @tswrightsandpointe",
            "title": "Maintenance"
        },
        {
            "location": "/whatsnew/#contributors",
            "text": "Besiders the core developers, we have seen an increase in outside contributions which we greatly appreciate. Specifically, these people contributed to this release:   Shane Bussman  @MridulS  @YihaoLu  @jkrauss82  @tswrightsandpointe  @cgdeboer",
            "title": "Contributors"
        },
        {
            "location": "/whatsnew/#v03-oct-23-2015",
            "text": "This is a major release from 0.2 that includes many exciting new features. We recommend that all users upgrade to this new version.",
            "title": "v0.3 (Oct 23, 2015)"
        },
        {
            "location": "/whatsnew/#new-features_5",
            "text": "Sector exposures: sum positions by sector given a dictionary or series of symbol to sector mappings  PR166  Ability to make cones with multiple shades stdev regions  PR168  Slippage sweep: See how an algorithm performs with various levels of slippage  PR170  Stochastic volatility model in Bayesian tear sheet  PR174  Ability to suppress display of position information  PR177",
            "title": "New features"
        },
        {
            "location": "/whatsnew/#bug-fixes_3",
            "text": "Various fixes to make pyfolio pandas 0.17 compatible",
            "title": "Bug fixes"
        },
        {
            "location": "/whatsnew/#v02-oct-16-2015",
            "text": "This is a major release from 0.1 that includes mainly bugfixes and refactorings but also some new features. We recommend that all users upgrade to this new version.",
            "title": "v0.2 (Oct 16, 2015)"
        },
        {
            "location": "/whatsnew/#new-features_6",
            "text": "Volatility matched cumulative returns plot  PR126 .  Allow for different periodicity (annualization factors) in the annual_() methods  PR164 .  Users can supply their own interesting periods  PR163 .  Ability to weight a portfolio of holdings by a metric valued  PR161 .",
            "title": "New features"
        },
        {
            "location": "/whatsnew/#bug-fixes_4",
            "text": "Fix drawdown overlaps  PR150 .  Monthly returns distribution should not stack by year  PR162 .  Fix gross leverage  PR147",
            "title": "Bug fixes"
        },
        {
            "location": "/notebooks/single_stock_example/",
            "text": "Single stock analysis example in pyfolio\n\n\nHere's a simple example where we produce a set of plots, called a tear sheet, for a stock.\n\n\nImport pyfolio\n\n\n%matplotlib inline\nimport pyfolio as pf\n\n\n\n\nFetch the daily returns for a stock\n\n\nstock_rets = pf.utils.get_symbol_rets('FB')\n\n\n\n\nCreate a full tear sheet for the single stock\n\n\nThis will show charts about returns and shock events.\n\n\npf.create_returns_tear_sheet(stock_rets, live_start_date='2015-12-1')\n\n\n\n\nEntire data start date: 2012-05-21\nEntire data end date: 2016-04-20\n\n\nOut-of-Sample Months: 4\nBacktest Months: 42\n\n\n\n\n\n\n  \n\n    \n\n      \nPerformance statistics\n\n      \nAll history\n\n      \nBacktest\n\n      \nOut of sample\n\n    \n\n  \n\n  \n\n    \n\n      \nannual_return\n\n      \n0.32\n\n      \n0.33\n\n      \n0.14\n\n    \n\n    \n\n      \nannual_volatility\n\n      \n0.43\n\n      \n0.43\n\n      \n0.38\n\n    \n\n    \n\n      \nsharpe_ratio\n\n      \n0.85\n\n      \n0.87\n\n      \n0.52\n\n    \n\n    \n\n      \ncalmar_ratio\n\n      \n0.66\n\n      \n0.69\n\n      \n1.00\n\n    \n\n    \n\n      \nstability_of_timeseries\n\n      \n0.95\n\n      \n0.94\n\n      \n0.59\n\n    \n\n    \n\n      \nmax_drawdown\n\n      \n-0.48\n\n      \n-0.48\n\n      \n-0.14\n\n    \n\n    \n\n      \nomega_ratio\n\n      \n1.18\n\n      \n1.18\n\n      \n1.11\n\n    \n\n    \n\n      \nsortino_ratio\n\n      \n1.38\n\n      \n1.39\n\n      \n0.89\n\n    \n\n    \n\n      \nskew\n\n      \n1.79\n\n      \n1.73\n\n      \n2.47\n\n    \n\n    \n\n      \nkurtosis\n\n      \n19.34\n\n      \n19.44\n\n      \n16.42\n\n    \n\n    \n\n      \ntail_ratio\n\n      \n1.03\n\n      \n1.04\n\n      \n0.85\n\n    \n\n    \n\n      \ncommon_sense_ratio\n\n      \n1.35\n\n      \n1.39\n\n      \n0.97\n\n    \n\n    \n\n      \ninformation_ratio\n\n      \n0.03\n\n      \n0.03\n\n      \n0.03\n\n    \n\n    \n\n      \nalpha\n\n      \n0.20\n\n      \n0.21\n\n      \n0.15\n\n    \n\n    \n\n      \nbeta\n\n      \n1.05\n\n      \n1.01\n\n      \n1.22\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nWorst Drawdown Periods\n\n      \nnet drawdown in %\n\n      \npeak date\n\n      \nvalley date\n\n      \nrecovery date\n\n      \nduration\n\n    \n\n  \n\n  \n\n    \n\n      \n1\n\n      \n47.90\n\n      \n2012-05-21\n\n      \n2012-09-04\n\n      \n2013-07-25\n\n      \n309\n\n    \n\n    \n\n      \n2\n\n      \n22.06\n\n      \n2014-03-10\n\n      \n2014-04-28\n\n      \n2014-07-24\n\n      \n99\n\n    \n\n    \n\n      \n0\n\n      \n16.57\n\n      \n2015-07-21\n\n      \n2015-08-24\n\n      \n2015-10-19\n\n      \n65\n\n    \n\n    \n\n      \n4\n\n      \n13.62\n\n      \n2015-11-11\n\n      \n2016-01-21\n\n      \n2016-01-28\n\n      \n57\n\n    \n\n    \n\n      \n3\n\n      \n13.51\n\n      \n2016-02-01\n\n      \n2016-02-09\n\n      \n2016-03-29\n\n      \n42\n\n    \n\n  \n\n\n\n\n\n\n\n[-0.052 -0.111]",
            "title": "Single stock"
        },
        {
            "location": "/notebooks/single_stock_example/#single-stock-analysis-example-in-pyfolio",
            "text": "Here's a simple example where we produce a set of plots, called a tear sheet, for a stock.",
            "title": "Single stock analysis example in pyfolio"
        },
        {
            "location": "/notebooks/single_stock_example/#import-pyfolio",
            "text": "%matplotlib inline\nimport pyfolio as pf",
            "title": "Import pyfolio"
        },
        {
            "location": "/notebooks/single_stock_example/#fetch-the-daily-returns-for-a-stock",
            "text": "stock_rets = pf.utils.get_symbol_rets('FB')",
            "title": "Fetch the daily returns for a stock"
        },
        {
            "location": "/notebooks/single_stock_example/#create-a-full-tear-sheet-for-the-single-stock",
            "text": "This will show charts about returns and shock events.  pf.create_returns_tear_sheet(stock_rets, live_start_date='2015-12-1')  Entire data start date: 2012-05-21\nEntire data end date: 2016-04-20\n\n\nOut-of-Sample Months: 4\nBacktest Months: 42   \n   \n     \n       Performance statistics \n       All history \n       Backtest \n       Out of sample \n     \n   \n   \n     \n       annual_return \n       0.32 \n       0.33 \n       0.14 \n     \n     \n       annual_volatility \n       0.43 \n       0.43 \n       0.38 \n     \n     \n       sharpe_ratio \n       0.85 \n       0.87 \n       0.52 \n     \n     \n       calmar_ratio \n       0.66 \n       0.69 \n       1.00 \n     \n     \n       stability_of_timeseries \n       0.95 \n       0.94 \n       0.59 \n     \n     \n       max_drawdown \n       -0.48 \n       -0.48 \n       -0.14 \n     \n     \n       omega_ratio \n       1.18 \n       1.18 \n       1.11 \n     \n     \n       sortino_ratio \n       1.38 \n       1.39 \n       0.89 \n     \n     \n       skew \n       1.79 \n       1.73 \n       2.47 \n     \n     \n       kurtosis \n       19.34 \n       19.44 \n       16.42 \n     \n     \n       tail_ratio \n       1.03 \n       1.04 \n       0.85 \n     \n     \n       common_sense_ratio \n       1.35 \n       1.39 \n       0.97 \n     \n     \n       information_ratio \n       0.03 \n       0.03 \n       0.03 \n     \n     \n       alpha \n       0.20 \n       0.21 \n       0.15 \n     \n     \n       beta \n       1.05 \n       1.01 \n       1.22 \n     \n       \n   \n     \n       Worst Drawdown Periods \n       net drawdown in % \n       peak date \n       valley date \n       recovery date \n       duration \n     \n   \n   \n     \n       1 \n       47.90 \n       2012-05-21 \n       2012-09-04 \n       2013-07-25 \n       309 \n     \n     \n       2 \n       22.06 \n       2014-03-10 \n       2014-04-28 \n       2014-07-24 \n       99 \n     \n     \n       0 \n       16.57 \n       2015-07-21 \n       2015-08-24 \n       2015-10-19 \n       65 \n     \n     \n       4 \n       13.62 \n       2015-11-11 \n       2016-01-21 \n       2016-01-28 \n       57 \n     \n     \n       3 \n       13.51 \n       2016-02-01 \n       2016-02-09 \n       2016-03-29 \n       42 \n     \n      [-0.052 -0.111]",
            "title": "Create a full tear sheet for the single stock"
        },
        {
            "location": "/notebooks/zipline_algo_example/",
            "text": "Zipline algorithm analysis example in pyfolio\n\n\nHere's an example where we run an algorithm with zipline, then produce tear sheets for that algorithm.\n\n\nImports\n\n\nImport pyfolio, along with the necessary modules for running our zipline backtest.\n\n\n%matplotlib inline\nimport pyfolio as pf\n\n\n\n\nimport sys\nimport logbook\nimport numpy as np\nfrom datetime import datetime\nimport pytz\n\nfrom zipline.algorithm import TradingAlgorithm\nfrom zipline.utils.factory import load_from_yahoo\nfrom zipline.finance import commission\n\n\n\n\nRun our zipline algorithm\n\n\nThis algorithm can also be adjusted to execute a modified, or completely different, trading strategy.\n\n\n# Zipline trading algorithm\n# Taken from zipline.examples.olmar\nzipline_logging = logbook.NestedSetup([\n    logbook.NullHandler(level=logbook.DEBUG),\n    logbook.StreamHandler(sys.stdout, level=logbook.INFO),\n    logbook.StreamHandler(sys.stderr, level=logbook.ERROR),\n])\nzipline_logging.push_application()\n\nSTOCKS = ['AMD', 'CERN', 'COST', 'DELL', 'GPS', 'INTC', 'MMM']\n\n\n# On-Line Portfolio Moving Average Reversion\n\n# More info can be found in the corresponding paper:\n# http://icml.cc/2012/papers/168.pdf\ndef initialize(algo, eps=1, window_length=5):\n    algo.stocks = STOCKS\n    algo.sids = [algo.symbol(symbol) for symbol in algo.stocks]\n    algo.m = len(algo.stocks)\n    algo.price = {}\n    algo.b_t = np.ones(algo.m) / algo.m\n    algo.last_desired_port = np.ones(algo.m) / algo.m\n    algo.eps = eps\n    algo.init = True\n    algo.days = 0\n    algo.window_length = window_length\n\n    algo.set_commission(commission.PerShare(cost=0))\n\n\ndef handle_data(algo, data):\n    algo.days += 1\n    if algo.days < algo.window_length:\n        return\n\n    if algo.init:\n        rebalance_portfolio(algo, data, algo.b_t)\n        algo.init = False\n        return\n\n    m = algo.m\n\n    x_tilde = np.zeros(m)\n    b = np.zeros(m)\n\n    # find relative moving average price for each asset\n    mavgs = data.history(algo.sids, 'price', algo.window_length, '1d').mean()\n    for i, sid in enumerate(algo.sids):\n        price = data.current(sid, \"price\")\n        # Relative mean deviation\n        x_tilde[i] = mavgs[sid] / price\n\n    ###########################\n    # Inside of OLMAR (algo 2)\n    x_bar = x_tilde.mean()\n\n    # market relative deviation\n    mark_rel_dev = x_tilde - x_bar\n\n    # Expected return with current portfolio\n    exp_return = np.dot(algo.b_t, x_tilde)\n    weight = algo.eps - exp_return\n    variability = (np.linalg.norm(mark_rel_dev)) ** 2\n\n    # test for divide-by-zero case\n    if variability == 0.0:\n        step_size = 0\n    else:\n        step_size = max(0, weight / variability)\n\n    b = algo.b_t + step_size * mark_rel_dev\n    b_norm = simplex_projection(b)\n    np.testing.assert_almost_equal(b_norm.sum(), 1)\n\n    rebalance_portfolio(algo, data, b_norm)\n\n    # update portfolio\n    algo.b_t = b_norm\n\n\ndef rebalance_portfolio(algo, data, desired_port):\n    # rebalance portfolio\n    desired_amount = np.zeros_like(desired_port)\n    current_amount = np.zeros_like(desired_port)\n    prices = np.zeros_like(desired_port)\n\n    if algo.init:\n        positions_value = algo.portfolio.starting_cash\n    else:\n        positions_value = algo.portfolio.positions_value + \\\n            algo.portfolio.cash\n\n    for i, sid in enumerate(algo.sids):\n        current_amount[i] = algo.portfolio.positions[sid].amount\n        prices[i] = data.current(sid, \"price\")\n\n    desired_amount = np.round(desired_port * positions_value / prices)\n\n    algo.last_desired_port = desired_port\n    diff_amount = desired_amount - current_amount\n\n    for i, sid in enumerate(algo.sids):\n        algo.order(sid, diff_amount[i])\n\n\ndef simplex_projection(v, b=1):\n    \"\"\"Projection vectors to the simplex domain\n    Implemented according to the paper: Efficient projections onto the\n    l1-ball for learning in high dimensions, John Duchi, et al. ICML 2008.\n    Implementation Time: 2011 June 17 by Bin@libin AT pmail.ntu.edu.sg\n    Optimization Problem: min_{w}\\| w - v \\|_{2}^{2}\n    s.t. sum_{i=1}^{m}=z, w_{i}\\geq 0\n    Input: A vector v \\in R^{m}, and a scalar z > 0 (default=1)\n    Output: Projection vector w\n    :Example:\n    >>> proj = simplex_projection([.4 ,.3, -.4, .5])\n    >>> print(proj)\n    array([ 0.33333333, 0.23333333, 0. , 0.43333333])\n    >>> print(proj.sum())\n    1.0\n    Original matlab implementation: John Duchi (jduchi@cs.berkeley.edu)\n    Python-port: Copyright 2013 by Thomas Wiecki (thomas.wiecki@gmail.com).\n    \"\"\"\n\n    v = np.asarray(v)\n    p = len(v)\n\n    # Sort v into u in descending order\n    v = (v > 0) * v\n    u = np.sort(v)[::-1]\n    sv = np.cumsum(u)\n\n    rho = np.where(u > (sv - b) / np.arange(1, p + 1))[0][-1]\n    theta = np.max([0, (sv[rho] - b) / (rho + 1)])\n    w = (v - theta)\n    w[w < 0] = 0\n    return w\n\n\nstart = datetime(2004, 1, 1, 0, 0, 0, 0, pytz.utc)\nend = datetime(2010, 1, 1, 0, 0, 0, 0, pytz.utc)\n\n# Load price data from yahoo.\ndata = load_from_yahoo(stocks=STOCKS, indexes={}, start=start, end=end)\ndata = data.dropna()\n\n# Create and run the algorithm.\nolmar = TradingAlgorithm(handle_data=handle_data, initialize=initialize)\nresults = olmar.run(data)\n\n\n\n\n[2016-04-21 09:37:33.915336] INFO: Loader: Loading stock: AMD\n[2016-04-21 09:37:33.926626] INFO: Loader: Loading stock: CERN\n[2016-04-21 09:37:33.936490] INFO: Loader: Loading stock: COST\n[2016-04-21 09:37:33.951613] INFO: Loader: Loading stock: DELL\n[2016-04-21 09:37:33.965023] INFO: Loader: Loading stock: GPS\n[2016-04-21 09:37:33.976631] INFO: Loader: Loading stock: INTC\n[2016-04-21 09:37:33.987218] INFO: Loader: Loading stock: MMM\n[2016-04-21 09:37:50.955240] INFO: Performance: Simulated 1511 trading days out of 1511.\n[2016-04-21 09:37:50.956092] INFO: Performance: first open: 2004-01-02 14:31:00+00:00\n[2016-04-21 09:37:50.956915] INFO: Performance: last close: 2009-12-31 21:00:00+00:00\n\n\n\nExtract metrics\n\n\nGet the returns, positions, and transactions from the zipline backtest object.\n\n\nreturns, positions, transactions, gross_lev = pf.utils.extract_rets_pos_txn_from_zipline(results)\n\n\n\n\nSingle plot example\n\n\nMake one plot of the top 5 drawdown periods.\n\n\npf.plot_drawdown_periods(returns, top=5).set_xlabel('Date')\n\n\n\n\n<matplotlib.text.Text at 0x7fd6ff3d9198>\n\n\n\n\n\nFull tear sheet example\n\n\nCreate a full tear sheet for our algorithm. As an example, set the live start date to something arbitrary.\n\n\npf.create_full_tear_sheet(returns, positions=positions, transactions=transactions,\n                          gross_lev=gross_lev, live_start_date='2009-10-22', round_trips=True)\n\n\n\n\nEntire data start date: 2004-01-02\nEntire data end date: 2009-12-31\n\n\nOut-of-Sample Months: 2\nBacktest Months: 69\n\n\n\n\n\n\n  \n\n    \n\n      \nPerformance statistics\n\n      \nAll history\n\n      \nBacktest\n\n      \nOut of sample\n\n    \n\n  \n\n  \n\n    \n\n      \nannual_return\n\n      \n0.08\n\n      \n0.08\n\n      \n0.03\n\n    \n\n    \n\n      \nannual_volatility\n\n      \n0.25\n\n      \n0.26\n\n      \n0.22\n\n    \n\n    \n\n      \nsharpe_ratio\n\n      \n0.44\n\n      \n0.43\n\n      \n0.25\n\n    \n\n    \n\n      \ncalmar_ratio\n\n      \n0.14\n\n      \n0.14\n\n      \n0.42\n\n    \n\n    \n\n      \nstability_of_timeseries\n\n      \n-0.01\n\n      \n-0.09\n\n      \n0.22\n\n    \n\n    \n\n      \nmax_drawdown\n\n      \n-0.60\n\n      \n-0.60\n\n      \n-0.07\n\n    \n\n    \n\n      \nomega_ratio\n\n      \n1.08\n\n      \n1.08\n\n      \n1.04\n\n    \n\n    \n\n      \nsortino_ratio\n\n      \n0.65\n\n      \n0.64\n\n      \n0.34\n\n    \n\n    \n\n      \nskew\n\n      \n0.27\n\n      \n0.28\n\n      \n-0.28\n\n    \n\n    \n\n      \nkurtosis\n\n      \n4.05\n\n      \n4.10\n\n      \n0.47\n\n    \n\n    \n\n      \ntail_ratio\n\n      \n0.97\n\n      \n0.99\n\n      \n1.24\n\n    \n\n    \n\n      \ncommon_sense_ratio\n\n      \n1.05\n\n      \n1.07\n\n      \n1.27\n\n    \n\n    \n\n      \ninformation_ratio\n\n      \n0.02\n\n      \n0.02\n\n      \n-0.05\n\n    \n\n    \n\n      \nalpha\n\n      \n0.08\n\n      \n0.08\n\n      \n-0.11\n\n    \n\n    \n\n      \nbeta\n\n      \n0.81\n\n      \n0.81\n\n      \n1.18\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nWorst Drawdown Periods\n\n      \nnet drawdown in %\n\n      \npeak date\n\n      \nvalley date\n\n      \nrecovery date\n\n      \nduration\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \n59.91\n\n      \n2007-11-06\n\n      \n2008-11-20\n\n      \nNaT\n\n      \nNaN\n\n    \n\n    \n\n      \n1\n\n      \n22.79\n\n      \n2006-02-16\n\n      \n2006-08-31\n\n      \n2007-05-22\n\n      \n329\n\n    \n\n    \n\n      \n2\n\n      \n12.70\n\n      \n2005-07-28\n\n      \n2005-10-12\n\n      \n2006-01-11\n\n      \n120\n\n    \n\n    \n\n      \n3\n\n      \n11.65\n\n      \n2004-11-15\n\n      \n2005-04-28\n\n      \n2005-07-28\n\n      \n184\n\n    \n\n    \n\n      \n4\n\n      \n9.50\n\n      \n2007-07-16\n\n      \n2007-08-06\n\n      \n2007-09-13\n\n      \n44\n\n    \n\n  \n\n\n\n\n\n\n\n[-0.032 -0.069]\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nStress Events\n\n      \nmean\n\n      \nmin\n\n      \nmax\n\n    \n\n  \n\n  \n\n    \n\n      \nLehmann\n\n      \n-0.26%\n\n      \n-4.45%\n\n      \n4.41%\n\n    \n\n    \n\n      \nAug07\n\n      \n0.34%\n\n      \n-2.96%\n\n      \n3.02%\n\n    \n\n    \n\n      \nMar08\n\n      \n-0.44%\n\n      \n-3.10%\n\n      \n3.33%\n\n    \n\n    \n\n      \nSept08\n\n      \n-0.64%\n\n      \n-4.35%\n\n      \n3.99%\n\n    \n\n    \n\n      \n2009Q1\n\n      \n-0.36%\n\n      \n-4.99%\n\n      \n3.35%\n\n    \n\n    \n\n      \n2009Q2\n\n      \n0.71%\n\n      \n-3.78%\n\n      \n6.15%\n\n    \n\n    \n\n      \nLow Volatility Bull Market\n\n      \n0.01%\n\n      \n-6.13%\n\n      \n6.40%\n\n    \n\n    \n\n      \nGFC Crash\n\n      \n-0.08%\n\n      \n-7.59%\n\n      \n9.70%\n\n    \n\n    \n\n      \nRecovery\n\n      \n0.32%\n\n      \n-3.78%\n\n      \n6.15%\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nTop 10 long positions of all time\n\n      \nmax\n\n    \n\n    \n\n      \nsid\n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \nEquity(3 [COST])\n\n      \n100.76%\n\n    \n\n    \n\n      \nEquity(7 [MMM])\n\n      \n92.38%\n\n    \n\n    \n\n      \nEquity(2 [CERN])\n\n      \n84.49%\n\n    \n\n    \n\n      \nEquity(4 [DELL])\n\n      \n71.71%\n\n    \n\n    \n\n      \nEquity(1 [AMD])\n\n      \n71.05%\n\n    \n\n    \n\n      \nEquity(6 [INTC])\n\n      \n66.55%\n\n    \n\n    \n\n      \nEquity(5 [GPS])\n\n      \n62.13%\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nTop 10 short positions of all time\n\n      \nmax\n\n    \n\n    \n\n      \nsid\n\n      \n\n    \n\n  \n\n  \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nTop 10 positions of all time\n\n      \nmax\n\n    \n\n    \n\n      \nsid\n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \nEquity(3 [COST])\n\n      \n100.76%\n\n    \n\n    \n\n      \nEquity(7 [MMM])\n\n      \n92.38%\n\n    \n\n    \n\n      \nEquity(2 [CERN])\n\n      \n84.49%\n\n    \n\n    \n\n      \nEquity(4 [DELL])\n\n      \n71.71%\n\n    \n\n    \n\n      \nEquity(1 [AMD])\n\n      \n71.05%\n\n    \n\n    \n\n      \nEquity(6 [INTC])\n\n      \n66.55%\n\n    \n\n    \n\n      \nEquity(5 [GPS])\n\n      \n62.13%\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nAll positions ever held\n\n      \nmax\n\n    \n\n    \n\n      \nsid\n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \nEquity(3 [COST])\n\n      \n100.76%\n\n    \n\n    \n\n      \nEquity(7 [MMM])\n\n      \n92.38%\n\n    \n\n    \n\n      \nEquity(2 [CERN])\n\n      \n84.49%\n\n    \n\n    \n\n      \nEquity(4 [DELL])\n\n      \n71.71%\n\n    \n\n    \n\n      \nEquity(1 [AMD])\n\n      \n71.05%\n\n    \n\n    \n\n      \nEquity(6 [INTC])\n\n      \n66.55%\n\n    \n\n    \n\n      \nEquity(5 [GPS])\n\n      \n62.13%\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nSummary stats\n\n      \nAll trades\n\n      \nLong trades\n\n    \n\n  \n\n  \n\n    \n\n      \nTotal number of round_trips\n\n      \n3729.00\n\n      \n3729.00\n\n    \n\n    \n\n      \nPercent profitable\n\n      \n0.43\n\n      \n0.43\n\n    \n\n    \n\n      \nWinning round_trips\n\n      \n1616.00\n\n      \n1616.00\n\n    \n\n    \n\n      \nLosing round_trips\n\n      \n2113.00\n\n      \n2113.00\n\n    \n\n    \n\n      \nEven round_trips\n\n      \n0.00\n\n      \n0.00\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nPnL stats\n\n      \nAll trades\n\n      \nLong trades\n\n    \n\n  \n\n  \n\n    \n\n      \nTotal profit\n\n      \n$61673.54\n\n      \n$61673.54\n\n    \n\n    \n\n      \nGross profit\n\n      \n$376899.39\n\n      \n$376899.39\n\n    \n\n    \n\n      \nGross loss\n\n      \n$-315225.85\n\n      \n$-315225.85\n\n    \n\n    \n\n      \nProfit factor\n\n      \n$1.20\n\n      \n$1.20\n\n    \n\n    \n\n      \nAvg. trade net profit\n\n      \n$16.54\n\n      \n$16.54\n\n    \n\n    \n\n      \nAvg. winning trade\n\n      \n$233.23\n\n      \n$233.23\n\n    \n\n    \n\n      \nAvg. losing trade\n\n      \n$-149.18\n\n      \n$-149.18\n\n    \n\n    \n\n      \nRatio Avg. Win:Avg. Loss\n\n      \n$1.56\n\n      \n$1.56\n\n    \n\n    \n\n      \nLargest winning trade\n\n      \n$15541.78\n\n      \n$15541.78\n\n    \n\n    \n\n      \nLargest losing trade\n\n      \n$-12468.25\n\n      \n$-12468.25\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nDuration stats\n\n      \nAll trades\n\n      \nLong trades\n\n    \n\n  \n\n  \n\n    \n\n      \nAvg duration\n\n      \n22 days 05:36:44.023330\n\n      \n22 days 05:36:44.023330\n\n    \n\n    \n\n      \nMedian duration\n\n      \n18 days 00:00:00\n\n      \n18 days 00:00:00\n\n    \n\n    \n\n      \nAvg # round_trips per day\n\n      \n34.53\n\n      \n34.53\n\n    \n\n    \n\n      \nAvg # round_trips per month\n\n      \n725.08\n\n      \n725.08\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nReturn stats\n\n      \nAll trades\n\n      \nLong trades\n\n    \n\n  \n\n  \n\n    \n\n      \nAvg returns all round_trips\n\n      \n0.01%\n\n      \n0.01%\n\n    \n\n    \n\n      \nAvg returns winning\n\n      \n0.19%\n\n      \n0.19%\n\n    \n\n    \n\n      \nAvg returns losing\n\n      \n-0.13%\n\n      \n-0.13%\n\n    \n\n    \n\n      \nMedian returns all round_trips\n\n      \n-0.00%\n\n      \n-0.00%\n\n    \n\n    \n\n      \nMedian returns winning\n\n      \n0.03%\n\n      \n0.03%\n\n    \n\n    \n\n      \nMedian returns losing\n\n      \n-0.01%\n\n      \n-0.01%\n\n    \n\n    \n\n      \nLargest winning trade\n\n      \n12.12%\n\n      \n12.12%\n\n    \n\n    \n\n      \nLargest losing trade\n\n      \n-9.15%\n\n      \n-9.15%\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nSymbol stats\n\n      \nEquity(1 [AMD])\n\n      \nEquity(2 [CERN])\n\n      \nEquity(3 [COST])\n\n      \nEquity(4 [DELL])\n\n      \nEquity(5 [GPS])\n\n      \nEquity(6 [INTC])\n\n      \nEquity(7 [MMM])\n\n    \n\n  \n\n  \n\n    \n\n      \nAvg returns all round_trips\n\n      \n-0.00%\n\n      \n0.03%\n\n      \n0.03%\n\n      \n-0.04%\n\n      \n-0.01%\n\n      \n0.04%\n\n      \n0.01%\n\n    \n\n    \n\n      \nAvg returns winning\n\n      \n0.41%\n\n      \n0.22%\n\n      \n0.15%\n\n      \n0.15%\n\n      \n0.15%\n\n      \n0.19%\n\n      \n0.12%\n\n    \n\n    \n\n      \nAvg returns losing\n\n      \n-0.34%\n\n      \n-0.15%\n\n      \n-0.06%\n\n      \n-0.18%\n\n      \n-0.10%\n\n      \n-0.07%\n\n      \n-0.08%\n\n    \n\n    \n\n      \nMedian returns all round_trips\n\n      \n-0.00%\n\n      \n-0.00%\n\n      \n-0.00%\n\n      \n-0.00%\n\n      \n-0.00%\n\n      \n-0.00%\n\n      \n-0.00%\n\n    \n\n    \n\n      \nMedian returns winning\n\n      \n0.10%\n\n      \n0.03%\n\n      \n0.03%\n\n      \n0.02%\n\n      \n0.04%\n\n      \n0.06%\n\n      \n0.02%\n\n    \n\n    \n\n      \nMedian returns losing\n\n      \n-0.02%\n\n      \n-0.01%\n\n      \n-0.01%\n\n      \n-0.01%\n\n      \n-0.01%\n\n      \n-0.00%\n\n      \n-0.01%\n\n    \n\n    \n\n      \nLargest winning trade\n\n      \n12.12%\n\n      \n5.91%\n\n      \n2.95%\n\n      \n2.48%\n\n      \n3.52%\n\n      \n2.32%\n\n      \n2.23%\n\n    \n\n    \n\n      \nLargest losing trade\n\n      \n-9.15%\n\n      \n-4.68%\n\n      \n-3.41%\n\n      \n-5.87%\n\n      \n-8.27%\n\n      \n-4.61%\n\n      \n-3.84%\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nProfitability (PnL / PnL total) per name\n\n      \npnl\n\n    \n\n    \n\n      \nsymbol\n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \nEquity(6 [INTC])\n\n      \n0.44%\n\n    \n\n    \n\n      \nEquity(3 [COST])\n\n      \n0.40%\n\n    \n\n    \n\n      \nEquity(2 [CERN])\n\n      \n0.34%\n\n    \n\n    \n\n      \nEquity(7 [MMM])\n\n      \n0.18%\n\n    \n\n    \n\n      \nEquity(5 [GPS])\n\n      \n0.02%\n\n    \n\n    \n\n      \nEquity(1 [AMD])\n\n      \n-0.06%\n\n    \n\n    \n\n      \nEquity(4 [DELL])\n\n      \n-0.32%\n\n    \n\n  \n\n\n\n\n\n\n\n<matplotlib.figure.Figure at 0x7fd6f7c5a6a0>\n\n\n\n\n\nSuppressing symbol output\n\n\nWhen sharing tear sheets it might be undesirable to display which symbols where used by a strategy. To suppress these in the tear sheet you can pass \nhide_positions=True\n.\n\n\npf.create_full_tear_sheet(returns, positions=positions, transactions=transactions,\n                          gross_lev=gross_lev, live_start_date='2009-10-22',\n                          hide_positions=True)\n\n\n\n\nEntire data start date: 2004-01-02\nEntire data end date: 2009-12-31\n\n\nOut-of-Sample Months: 2\nBacktest Months: 69\n\n\n\n\n\n\n  \n\n    \n\n      \nPerformance statistics\n\n      \nAll history\n\n      \nBacktest\n\n      \nOut of sample\n\n    \n\n  \n\n  \n\n    \n\n      \nannual_return\n\n      \n0.08\n\n      \n0.08\n\n      \n0.03\n\n    \n\n    \n\n      \nannual_volatility\n\n      \n0.25\n\n      \n0.26\n\n      \n0.22\n\n    \n\n    \n\n      \nsharpe_ratio\n\n      \n0.44\n\n      \n0.43\n\n      \n0.25\n\n    \n\n    \n\n      \ncalmar_ratio\n\n      \n0.14\n\n      \n0.14\n\n      \n0.42\n\n    \n\n    \n\n      \nstability_of_timeseries\n\n      \n-0.01\n\n      \n-0.09\n\n      \n0.22\n\n    \n\n    \n\n      \nmax_drawdown\n\n      \n-0.60\n\n      \n-0.60\n\n      \n-0.07\n\n    \n\n    \n\n      \nomega_ratio\n\n      \n1.08\n\n      \n1.08\n\n      \n1.04\n\n    \n\n    \n\n      \nsortino_ratio\n\n      \n0.65\n\n      \n0.64\n\n      \n0.34\n\n    \n\n    \n\n      \nskew\n\n      \n0.27\n\n      \n0.28\n\n      \n-0.28\n\n    \n\n    \n\n      \nkurtosis\n\n      \n4.05\n\n      \n4.10\n\n      \n0.47\n\n    \n\n    \n\n      \ntail_ratio\n\n      \n0.97\n\n      \n0.99\n\n      \n1.24\n\n    \n\n    \n\n      \ncommon_sense_ratio\n\n      \n1.05\n\n      \n1.07\n\n      \n1.27\n\n    \n\n    \n\n      \ninformation_ratio\n\n      \n0.02\n\n      \n0.02\n\n      \n-0.05\n\n    \n\n    \n\n      \nalpha\n\n      \n0.08\n\n      \n0.08\n\n      \n-0.11\n\n    \n\n    \n\n      \nbeta\n\n      \n0.81\n\n      \n0.81\n\n      \n1.18\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nWorst Drawdown Periods\n\n      \nnet drawdown in %\n\n      \npeak date\n\n      \nvalley date\n\n      \nrecovery date\n\n      \nduration\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \n59.91\n\n      \n2007-11-06\n\n      \n2008-11-20\n\n      \nNaT\n\n      \nNaN\n\n    \n\n    \n\n      \n1\n\n      \n22.79\n\n      \n2006-02-16\n\n      \n2006-08-31\n\n      \n2007-05-22\n\n      \n329\n\n    \n\n    \n\n      \n2\n\n      \n12.70\n\n      \n2005-07-28\n\n      \n2005-10-12\n\n      \n2006-01-11\n\n      \n120\n\n    \n\n    \n\n      \n3\n\n      \n11.65\n\n      \n2004-11-15\n\n      \n2005-04-28\n\n      \n2005-07-28\n\n      \n184\n\n    \n\n    \n\n      \n4\n\n      \n9.50\n\n      \n2007-07-16\n\n      \n2007-08-06\n\n      \n2007-09-13\n\n      \n44\n\n    \n\n  \n\n\n\n\n\n\n\n[-0.032 -0.069]\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nStress Events\n\n      \nmean\n\n      \nmin\n\n      \nmax\n\n    \n\n  \n\n  \n\n    \n\n      \nLehmann\n\n      \n-0.26%\n\n      \n-4.45%\n\n      \n4.41%\n\n    \n\n    \n\n      \nAug07\n\n      \n0.34%\n\n      \n-2.96%\n\n      \n3.02%\n\n    \n\n    \n\n      \nMar08\n\n      \n-0.44%\n\n      \n-3.10%\n\n      \n3.33%\n\n    \n\n    \n\n      \nSept08\n\n      \n-0.64%\n\n      \n-4.35%\n\n      \n3.99%\n\n    \n\n    \n\n      \n2009Q1\n\n      \n-0.36%\n\n      \n-4.99%\n\n      \n3.35%\n\n    \n\n    \n\n      \n2009Q2\n\n      \n0.71%\n\n      \n-3.78%\n\n      \n6.15%\n\n    \n\n    \n\n      \nLow Volatility Bull Market\n\n      \n0.01%\n\n      \n-6.13%\n\n      \n6.40%\n\n    \n\n    \n\n      \nGFC Crash\n\n      \n-0.08%\n\n      \n-7.59%\n\n      \n9.70%\n\n    \n\n    \n\n      \nRecovery\n\n      \n0.32%\n\n      \n-3.78%\n\n      \n6.15%",
            "title": "Zipline algorithm"
        },
        {
            "location": "/notebooks/zipline_algo_example/#zipline-algorithm-analysis-example-in-pyfolio",
            "text": "Here's an example where we run an algorithm with zipline, then produce tear sheets for that algorithm.",
            "title": "Zipline algorithm analysis example in pyfolio"
        },
        {
            "location": "/notebooks/zipline_algo_example/#imports",
            "text": "Import pyfolio, along with the necessary modules for running our zipline backtest.  %matplotlib inline\nimport pyfolio as pf  import sys\nimport logbook\nimport numpy as np\nfrom datetime import datetime\nimport pytz\n\nfrom zipline.algorithm import TradingAlgorithm\nfrom zipline.utils.factory import load_from_yahoo\nfrom zipline.finance import commission",
            "title": "Imports"
        },
        {
            "location": "/notebooks/zipline_algo_example/#run-our-zipline-algorithm",
            "text": "This algorithm can also be adjusted to execute a modified, or completely different, trading strategy.  # Zipline trading algorithm\n# Taken from zipline.examples.olmar\nzipline_logging = logbook.NestedSetup([\n    logbook.NullHandler(level=logbook.DEBUG),\n    logbook.StreamHandler(sys.stdout, level=logbook.INFO),\n    logbook.StreamHandler(sys.stderr, level=logbook.ERROR),\n])\nzipline_logging.push_application()\n\nSTOCKS = ['AMD', 'CERN', 'COST', 'DELL', 'GPS', 'INTC', 'MMM']\n\n\n# On-Line Portfolio Moving Average Reversion\n\n# More info can be found in the corresponding paper:\n# http://icml.cc/2012/papers/168.pdf\ndef initialize(algo, eps=1, window_length=5):\n    algo.stocks = STOCKS\n    algo.sids = [algo.symbol(symbol) for symbol in algo.stocks]\n    algo.m = len(algo.stocks)\n    algo.price = {}\n    algo.b_t = np.ones(algo.m) / algo.m\n    algo.last_desired_port = np.ones(algo.m) / algo.m\n    algo.eps = eps\n    algo.init = True\n    algo.days = 0\n    algo.window_length = window_length\n\n    algo.set_commission(commission.PerShare(cost=0))\n\n\ndef handle_data(algo, data):\n    algo.days += 1\n    if algo.days < algo.window_length:\n        return\n\n    if algo.init:\n        rebalance_portfolio(algo, data, algo.b_t)\n        algo.init = False\n        return\n\n    m = algo.m\n\n    x_tilde = np.zeros(m)\n    b = np.zeros(m)\n\n    # find relative moving average price for each asset\n    mavgs = data.history(algo.sids, 'price', algo.window_length, '1d').mean()\n    for i, sid in enumerate(algo.sids):\n        price = data.current(sid, \"price\")\n        # Relative mean deviation\n        x_tilde[i] = mavgs[sid] / price\n\n    ###########################\n    # Inside of OLMAR (algo 2)\n    x_bar = x_tilde.mean()\n\n    # market relative deviation\n    mark_rel_dev = x_tilde - x_bar\n\n    # Expected return with current portfolio\n    exp_return = np.dot(algo.b_t, x_tilde)\n    weight = algo.eps - exp_return\n    variability = (np.linalg.norm(mark_rel_dev)) ** 2\n\n    # test for divide-by-zero case\n    if variability == 0.0:\n        step_size = 0\n    else:\n        step_size = max(0, weight / variability)\n\n    b = algo.b_t + step_size * mark_rel_dev\n    b_norm = simplex_projection(b)\n    np.testing.assert_almost_equal(b_norm.sum(), 1)\n\n    rebalance_portfolio(algo, data, b_norm)\n\n    # update portfolio\n    algo.b_t = b_norm\n\n\ndef rebalance_portfolio(algo, data, desired_port):\n    # rebalance portfolio\n    desired_amount = np.zeros_like(desired_port)\n    current_amount = np.zeros_like(desired_port)\n    prices = np.zeros_like(desired_port)\n\n    if algo.init:\n        positions_value = algo.portfolio.starting_cash\n    else:\n        positions_value = algo.portfolio.positions_value + \\\n            algo.portfolio.cash\n\n    for i, sid in enumerate(algo.sids):\n        current_amount[i] = algo.portfolio.positions[sid].amount\n        prices[i] = data.current(sid, \"price\")\n\n    desired_amount = np.round(desired_port * positions_value / prices)\n\n    algo.last_desired_port = desired_port\n    diff_amount = desired_amount - current_amount\n\n    for i, sid in enumerate(algo.sids):\n        algo.order(sid, diff_amount[i])\n\n\ndef simplex_projection(v, b=1):\n    \"\"\"Projection vectors to the simplex domain\n    Implemented according to the paper: Efficient projections onto the\n    l1-ball for learning in high dimensions, John Duchi, et al. ICML 2008.\n    Implementation Time: 2011 June 17 by Bin@libin AT pmail.ntu.edu.sg\n    Optimization Problem: min_{w}\\| w - v \\|_{2}^{2}\n    s.t. sum_{i=1}^{m}=z, w_{i}\\geq 0\n    Input: A vector v \\in R^{m}, and a scalar z > 0 (default=1)\n    Output: Projection vector w\n    :Example:\n    >>> proj = simplex_projection([.4 ,.3, -.4, .5])\n    >>> print(proj)\n    array([ 0.33333333, 0.23333333, 0. , 0.43333333])\n    >>> print(proj.sum())\n    1.0\n    Original matlab implementation: John Duchi (jduchi@cs.berkeley.edu)\n    Python-port: Copyright 2013 by Thomas Wiecki (thomas.wiecki@gmail.com).\n    \"\"\"\n\n    v = np.asarray(v)\n    p = len(v)\n\n    # Sort v into u in descending order\n    v = (v > 0) * v\n    u = np.sort(v)[::-1]\n    sv = np.cumsum(u)\n\n    rho = np.where(u > (sv - b) / np.arange(1, p + 1))[0][-1]\n    theta = np.max([0, (sv[rho] - b) / (rho + 1)])\n    w = (v - theta)\n    w[w < 0] = 0\n    return w\n\n\nstart = datetime(2004, 1, 1, 0, 0, 0, 0, pytz.utc)\nend = datetime(2010, 1, 1, 0, 0, 0, 0, pytz.utc)\n\n# Load price data from yahoo.\ndata = load_from_yahoo(stocks=STOCKS, indexes={}, start=start, end=end)\ndata = data.dropna()\n\n# Create and run the algorithm.\nolmar = TradingAlgorithm(handle_data=handle_data, initialize=initialize)\nresults = olmar.run(data)  [2016-04-21 09:37:33.915336] INFO: Loader: Loading stock: AMD\n[2016-04-21 09:37:33.926626] INFO: Loader: Loading stock: CERN\n[2016-04-21 09:37:33.936490] INFO: Loader: Loading stock: COST\n[2016-04-21 09:37:33.951613] INFO: Loader: Loading stock: DELL\n[2016-04-21 09:37:33.965023] INFO: Loader: Loading stock: GPS\n[2016-04-21 09:37:33.976631] INFO: Loader: Loading stock: INTC\n[2016-04-21 09:37:33.987218] INFO: Loader: Loading stock: MMM\n[2016-04-21 09:37:50.955240] INFO: Performance: Simulated 1511 trading days out of 1511.\n[2016-04-21 09:37:50.956092] INFO: Performance: first open: 2004-01-02 14:31:00+00:00\n[2016-04-21 09:37:50.956915] INFO: Performance: last close: 2009-12-31 21:00:00+00:00",
            "title": "Run our zipline algorithm"
        },
        {
            "location": "/notebooks/zipline_algo_example/#extract-metrics",
            "text": "Get the returns, positions, and transactions from the zipline backtest object.  returns, positions, transactions, gross_lev = pf.utils.extract_rets_pos_txn_from_zipline(results)",
            "title": "Extract metrics"
        },
        {
            "location": "/notebooks/zipline_algo_example/#single-plot-example",
            "text": "Make one plot of the top 5 drawdown periods.  pf.plot_drawdown_periods(returns, top=5).set_xlabel('Date')  <matplotlib.text.Text at 0x7fd6ff3d9198>",
            "title": "Single plot example"
        },
        {
            "location": "/notebooks/zipline_algo_example/#full-tear-sheet-example",
            "text": "Create a full tear sheet for our algorithm. As an example, set the live start date to something arbitrary.  pf.create_full_tear_sheet(returns, positions=positions, transactions=transactions,\n                          gross_lev=gross_lev, live_start_date='2009-10-22', round_trips=True)  Entire data start date: 2004-01-02\nEntire data end date: 2009-12-31\n\n\nOut-of-Sample Months: 2\nBacktest Months: 69   \n   \n     \n       Performance statistics \n       All history \n       Backtest \n       Out of sample \n     \n   \n   \n     \n       annual_return \n       0.08 \n       0.08 \n       0.03 \n     \n     \n       annual_volatility \n       0.25 \n       0.26 \n       0.22 \n     \n     \n       sharpe_ratio \n       0.44 \n       0.43 \n       0.25 \n     \n     \n       calmar_ratio \n       0.14 \n       0.14 \n       0.42 \n     \n     \n       stability_of_timeseries \n       -0.01 \n       -0.09 \n       0.22 \n     \n     \n       max_drawdown \n       -0.60 \n       -0.60 \n       -0.07 \n     \n     \n       omega_ratio \n       1.08 \n       1.08 \n       1.04 \n     \n     \n       sortino_ratio \n       0.65 \n       0.64 \n       0.34 \n     \n     \n       skew \n       0.27 \n       0.28 \n       -0.28 \n     \n     \n       kurtosis \n       4.05 \n       4.10 \n       0.47 \n     \n     \n       tail_ratio \n       0.97 \n       0.99 \n       1.24 \n     \n     \n       common_sense_ratio \n       1.05 \n       1.07 \n       1.27 \n     \n     \n       information_ratio \n       0.02 \n       0.02 \n       -0.05 \n     \n     \n       alpha \n       0.08 \n       0.08 \n       -0.11 \n     \n     \n       beta \n       0.81 \n       0.81 \n       1.18 \n     \n       \n   \n     \n       Worst Drawdown Periods \n       net drawdown in % \n       peak date \n       valley date \n       recovery date \n       duration \n     \n   \n   \n     \n       0 \n       59.91 \n       2007-11-06 \n       2008-11-20 \n       NaT \n       NaN \n     \n     \n       1 \n       22.79 \n       2006-02-16 \n       2006-08-31 \n       2007-05-22 \n       329 \n     \n     \n       2 \n       12.70 \n       2005-07-28 \n       2005-10-12 \n       2006-01-11 \n       120 \n     \n     \n       3 \n       11.65 \n       2004-11-15 \n       2005-04-28 \n       2005-07-28 \n       184 \n     \n     \n       4 \n       9.50 \n       2007-07-16 \n       2007-08-06 \n       2007-09-13 \n       44 \n     \n      [-0.032 -0.069]    \n   \n     \n       Stress Events \n       mean \n       min \n       max \n     \n   \n   \n     \n       Lehmann \n       -0.26% \n       -4.45% \n       4.41% \n     \n     \n       Aug07 \n       0.34% \n       -2.96% \n       3.02% \n     \n     \n       Mar08 \n       -0.44% \n       -3.10% \n       3.33% \n     \n     \n       Sept08 \n       -0.64% \n       -4.35% \n       3.99% \n     \n     \n       2009Q1 \n       -0.36% \n       -4.99% \n       3.35% \n     \n     \n       2009Q2 \n       0.71% \n       -3.78% \n       6.15% \n     \n     \n       Low Volatility Bull Market \n       0.01% \n       -6.13% \n       6.40% \n     \n     \n       GFC Crash \n       -0.08% \n       -7.59% \n       9.70% \n     \n     \n       Recovery \n       0.32% \n       -3.78% \n       6.15% \n     \n        \n   \n     \n       Top 10 long positions of all time \n       max \n     \n     \n       sid \n       \n     \n   \n   \n     \n       Equity(3 [COST]) \n       100.76% \n     \n     \n       Equity(7 [MMM]) \n       92.38% \n     \n     \n       Equity(2 [CERN]) \n       84.49% \n     \n     \n       Equity(4 [DELL]) \n       71.71% \n     \n     \n       Equity(1 [AMD]) \n       71.05% \n     \n     \n       Equity(6 [INTC]) \n       66.55% \n     \n     \n       Equity(5 [GPS]) \n       62.13% \n     \n       \n   \n     \n       Top 10 short positions of all time \n       max \n     \n     \n       sid \n       \n     \n   \n   \n       \n   \n     \n       Top 10 positions of all time \n       max \n     \n     \n       sid \n       \n     \n   \n   \n     \n       Equity(3 [COST]) \n       100.76% \n     \n     \n       Equity(7 [MMM]) \n       92.38% \n     \n     \n       Equity(2 [CERN]) \n       84.49% \n     \n     \n       Equity(4 [DELL]) \n       71.71% \n     \n     \n       Equity(1 [AMD]) \n       71.05% \n     \n     \n       Equity(6 [INTC]) \n       66.55% \n     \n     \n       Equity(5 [GPS]) \n       62.13% \n     \n       \n   \n     \n       All positions ever held \n       max \n     \n     \n       sid \n       \n     \n   \n   \n     \n       Equity(3 [COST]) \n       100.76% \n     \n     \n       Equity(7 [MMM]) \n       92.38% \n     \n     \n       Equity(2 [CERN]) \n       84.49% \n     \n     \n       Equity(4 [DELL]) \n       71.71% \n     \n     \n       Equity(1 [AMD]) \n       71.05% \n     \n     \n       Equity(6 [INTC]) \n       66.55% \n     \n     \n       Equity(5 [GPS]) \n       62.13% \n     \n         \n   \n     \n       Summary stats \n       All trades \n       Long trades \n     \n   \n   \n     \n       Total number of round_trips \n       3729.00 \n       3729.00 \n     \n     \n       Percent profitable \n       0.43 \n       0.43 \n     \n     \n       Winning round_trips \n       1616.00 \n       1616.00 \n     \n     \n       Losing round_trips \n       2113.00 \n       2113.00 \n     \n     \n       Even round_trips \n       0.00 \n       0.00 \n     \n       \n   \n     \n       PnL stats \n       All trades \n       Long trades \n     \n   \n   \n     \n       Total profit \n       $61673.54 \n       $61673.54 \n     \n     \n       Gross profit \n       $376899.39 \n       $376899.39 \n     \n     \n       Gross loss \n       $-315225.85 \n       $-315225.85 \n     \n     \n       Profit factor \n       $1.20 \n       $1.20 \n     \n     \n       Avg. trade net profit \n       $16.54 \n       $16.54 \n     \n     \n       Avg. winning trade \n       $233.23 \n       $233.23 \n     \n     \n       Avg. losing trade \n       $-149.18 \n       $-149.18 \n     \n     \n       Ratio Avg. Win:Avg. Loss \n       $1.56 \n       $1.56 \n     \n     \n       Largest winning trade \n       $15541.78 \n       $15541.78 \n     \n     \n       Largest losing trade \n       $-12468.25 \n       $-12468.25 \n     \n       \n   \n     \n       Duration stats \n       All trades \n       Long trades \n     \n   \n   \n     \n       Avg duration \n       22 days 05:36:44.023330 \n       22 days 05:36:44.023330 \n     \n     \n       Median duration \n       18 days 00:00:00 \n       18 days 00:00:00 \n     \n     \n       Avg # round_trips per day \n       34.53 \n       34.53 \n     \n     \n       Avg # round_trips per month \n       725.08 \n       725.08 \n     \n       \n   \n     \n       Return stats \n       All trades \n       Long trades \n     \n   \n   \n     \n       Avg returns all round_trips \n       0.01% \n       0.01% \n     \n     \n       Avg returns winning \n       0.19% \n       0.19% \n     \n     \n       Avg returns losing \n       -0.13% \n       -0.13% \n     \n     \n       Median returns all round_trips \n       -0.00% \n       -0.00% \n     \n     \n       Median returns winning \n       0.03% \n       0.03% \n     \n     \n       Median returns losing \n       -0.01% \n       -0.01% \n     \n     \n       Largest winning trade \n       12.12% \n       12.12% \n     \n     \n       Largest losing trade \n       -9.15% \n       -9.15% \n     \n       \n   \n     \n       Symbol stats \n       Equity(1 [AMD]) \n       Equity(2 [CERN]) \n       Equity(3 [COST]) \n       Equity(4 [DELL]) \n       Equity(5 [GPS]) \n       Equity(6 [INTC]) \n       Equity(7 [MMM]) \n     \n   \n   \n     \n       Avg returns all round_trips \n       -0.00% \n       0.03% \n       0.03% \n       -0.04% \n       -0.01% \n       0.04% \n       0.01% \n     \n     \n       Avg returns winning \n       0.41% \n       0.22% \n       0.15% \n       0.15% \n       0.15% \n       0.19% \n       0.12% \n     \n     \n       Avg returns losing \n       -0.34% \n       -0.15% \n       -0.06% \n       -0.18% \n       -0.10% \n       -0.07% \n       -0.08% \n     \n     \n       Median returns all round_trips \n       -0.00% \n       -0.00% \n       -0.00% \n       -0.00% \n       -0.00% \n       -0.00% \n       -0.00% \n     \n     \n       Median returns winning \n       0.10% \n       0.03% \n       0.03% \n       0.02% \n       0.04% \n       0.06% \n       0.02% \n     \n     \n       Median returns losing \n       -0.02% \n       -0.01% \n       -0.01% \n       -0.01% \n       -0.01% \n       -0.00% \n       -0.01% \n     \n     \n       Largest winning trade \n       12.12% \n       5.91% \n       2.95% \n       2.48% \n       3.52% \n       2.32% \n       2.23% \n     \n     \n       Largest losing trade \n       -9.15% \n       -4.68% \n       -3.41% \n       -5.87% \n       -8.27% \n       -4.61% \n       -3.84% \n     \n       \n   \n     \n       Profitability (PnL / PnL total) per name \n       pnl \n     \n     \n       symbol \n       \n     \n   \n   \n     \n       Equity(6 [INTC]) \n       0.44% \n     \n     \n       Equity(3 [COST]) \n       0.40% \n     \n     \n       Equity(2 [CERN]) \n       0.34% \n     \n     \n       Equity(7 [MMM]) \n       0.18% \n     \n     \n       Equity(5 [GPS]) \n       0.02% \n     \n     \n       Equity(1 [AMD]) \n       -0.06% \n     \n     \n       Equity(4 [DELL]) \n       -0.32% \n     \n      <matplotlib.figure.Figure at 0x7fd6f7c5a6a0>",
            "title": "Full tear sheet example"
        },
        {
            "location": "/notebooks/zipline_algo_example/#suppressing-symbol-output",
            "text": "When sharing tear sheets it might be undesirable to display which symbols where used by a strategy. To suppress these in the tear sheet you can pass  hide_positions=True .  pf.create_full_tear_sheet(returns, positions=positions, transactions=transactions,\n                          gross_lev=gross_lev, live_start_date='2009-10-22',\n                          hide_positions=True)  Entire data start date: 2004-01-02\nEntire data end date: 2009-12-31\n\n\nOut-of-Sample Months: 2\nBacktest Months: 69   \n   \n     \n       Performance statistics \n       All history \n       Backtest \n       Out of sample \n     \n   \n   \n     \n       annual_return \n       0.08 \n       0.08 \n       0.03 \n     \n     \n       annual_volatility \n       0.25 \n       0.26 \n       0.22 \n     \n     \n       sharpe_ratio \n       0.44 \n       0.43 \n       0.25 \n     \n     \n       calmar_ratio \n       0.14 \n       0.14 \n       0.42 \n     \n     \n       stability_of_timeseries \n       -0.01 \n       -0.09 \n       0.22 \n     \n     \n       max_drawdown \n       -0.60 \n       -0.60 \n       -0.07 \n     \n     \n       omega_ratio \n       1.08 \n       1.08 \n       1.04 \n     \n     \n       sortino_ratio \n       0.65 \n       0.64 \n       0.34 \n     \n     \n       skew \n       0.27 \n       0.28 \n       -0.28 \n     \n     \n       kurtosis \n       4.05 \n       4.10 \n       0.47 \n     \n     \n       tail_ratio \n       0.97 \n       0.99 \n       1.24 \n     \n     \n       common_sense_ratio \n       1.05 \n       1.07 \n       1.27 \n     \n     \n       information_ratio \n       0.02 \n       0.02 \n       -0.05 \n     \n     \n       alpha \n       0.08 \n       0.08 \n       -0.11 \n     \n     \n       beta \n       0.81 \n       0.81 \n       1.18 \n     \n       \n   \n     \n       Worst Drawdown Periods \n       net drawdown in % \n       peak date \n       valley date \n       recovery date \n       duration \n     \n   \n   \n     \n       0 \n       59.91 \n       2007-11-06 \n       2008-11-20 \n       NaT \n       NaN \n     \n     \n       1 \n       22.79 \n       2006-02-16 \n       2006-08-31 \n       2007-05-22 \n       329 \n     \n     \n       2 \n       12.70 \n       2005-07-28 \n       2005-10-12 \n       2006-01-11 \n       120 \n     \n     \n       3 \n       11.65 \n       2004-11-15 \n       2005-04-28 \n       2005-07-28 \n       184 \n     \n     \n       4 \n       9.50 \n       2007-07-16 \n       2007-08-06 \n       2007-09-13 \n       44 \n     \n      [-0.032 -0.069]    \n   \n     \n       Stress Events \n       mean \n       min \n       max \n     \n   \n   \n     \n       Lehmann \n       -0.26% \n       -4.45% \n       4.41% \n     \n     \n       Aug07 \n       0.34% \n       -2.96% \n       3.02% \n     \n     \n       Mar08 \n       -0.44% \n       -3.10% \n       3.33% \n     \n     \n       Sept08 \n       -0.64% \n       -4.35% \n       3.99% \n     \n     \n       2009Q1 \n       -0.36% \n       -4.99% \n       3.35% \n     \n     \n       2009Q2 \n       0.71% \n       -3.78% \n       6.15% \n     \n     \n       Low Volatility Bull Market \n       0.01% \n       -6.13% \n       6.40% \n     \n     \n       GFC Crash \n       -0.08% \n       -7.59% \n       9.70% \n     \n     \n       Recovery \n       0.32% \n       -3.78% \n       6.15%",
            "title": "Suppressing symbol output"
        },
        {
            "location": "/notebooks/bayesian/",
            "text": "Bayesian performance analysis example in pyfolio\n\n\nThere are also a few more advanced (and still experimental) analysis methods in pyfolio based on Bayesian statistics. \n\n\nThe main benefit of these methods is \nuncertainty quantification\n. All the values you saw above, like the Sharpe ratio, are just single numbers. These estimates are noisy because they have been computed over a limited number of data points. So how much can you trust these numbers? You don't know because there is no sense of uncertainty. That is where Bayesian statistics helps as instead of single values, we are dealing with probability distributions that assign degrees of belief to all possible parameter values.\n\n\nLets create the Bayesian tear sheet. Under the hood this is running MCMC sampling in \nPyMC3\n to estimate the posteriors which can take quite a while (that's the reason why we don't generate this by default in \ncreate_full_tear_sheet()\n).\n\n\nImport pyfolio\n\n\n%matplotlib inline\nimport pyfolio as pf\n\n\n\n\nFetch the daily returns for a stock\n\n\nstock_rets = pf.utils.get_symbol_rets('FB')\n\n\n\n\nCreate Bayesian tear sheet\n\n\nout_of_sample = stock_rets.index[-40]\n\n\n\n\npf.create_bayesian_tear_sheet(stock_rets, live_start_date=out_of_sample)\n\n\n\n\nRunning T model\n\n\nWARNING (theano.gof.compilelock): Overriding existing lock by dead process '23486' (I am process '24728')\n\n\nApplied log-transform to volatility and added transformed volatility_log to model.\nApplied log-transform to nu_minus_two and added transformed nu_minus_two_log to model.\n [-----------------100%-----------------] 2000 of 2000 complete in 14.8 sec\nFinished T model (required 279.00 seconds).\n\nRunning BEST model\nApplied interval-transform to group1_std and added transformed group1_std_interval to model.\nApplied interval-transform to group2_std and added transformed group2_std_interval to model.\nApplied log-transform to nu_minus_two and added transformed nu_minus_two_log to model.\n [-----------------100%-----------------] 2000 of 2000 complete in 12.6 sec\nFinished BEST model (required 132.06 seconds).\n\nFinished plotting Bayesian cone (required 0.21 seconds).\n\n\n/home/wiecki/miniconda3/lib/python3.5/site-packages/matplotlib/axes/_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n  warnings.warn(\"No labelled objects found. \"\n\n\n\nFinished plotting BEST results (required 1.45 seconds).\n\nFinished computing Bayesian predictions (required 0.26 seconds).\n\nFinished plotting Bayesian VaRs estimate (required 0.12 seconds).\n\nRunning alpha beta model\nApplied log-transform to sigma and added transformed sigma_log to model.\nApplied log-transform to nu_minus_two and added transformed nu_minus_two_log to model.\n [-----------------100%-----------------] 2000 of 2000 complete in 7.2 sec\nFinished running alpha beta model (required 130.28 seconds).\n\nFinished plotting alpha beta model (required 0.24 seconds).\n\nTotal runtime was 543.62 seconds.\n\n\n\n\n\nLets go through these row by row:\n\n\n\n\nThe first one is the Bayesian cone plot that is the result of a summer internship project of Sepideh Sadeghi here at Quantopian. It's similar to the cone plot you already saw in the tear sheet above but has two critical additions: (i) it takes uncertainty into account (i.e. a short backtest length will result in a wider cone), and (ii) it does not assume normality of returns but instead uses a \nStudent-T distribution\n with heavier tails.\n\n\nThe next row compares mean returns of the in-sample (backest) and out-of-sample or OOS (forward) period. As you can see, mean returns are not a single number but a (posterior) distribution that gives us an indication of how certain we can be in our estimates. The green distribution on the left side is much wider, representing our increased uncertainty due to having less OOS data. We can then calculate the difference between these two distributions as shown on the right side. The grey lines denote the 2.5% and 97.5% percentiles. Intuitively, if the right grey line is lower than 0 you can say that with probability > 97.5% the OOS mean returns are below what is suggested by the backtest. The model used here is called \nBEST\n and was developed by John Kruschke.\n\n\nThe next couple of rows follow the same pattern but are an estimate of annual volatility, Sharpe ratio and their respective differences.\n\n\nThe 5th row shows the effect size or the difference of means normalized by the standard deviation and gives you a general sense how far apart the two distributions are. Intuitively, even if the means are significantly different, it may not be very meaningful if the standard deviation is huge amounting to a tiny difference of the two returns distributions.\n\n\nThe 6th row shows predicted returns (based on the backtest) for tomorrow, and 5 days from now. The blue line indicates the probability of losing more than 5% of your portfolio value and can be interpeted as a Bayesian VaR estimate.\n\n\nThe 7th row shows a Bayesian estimate of annual alpha and beta. In addition to uncertainty estimates, this model, like all above ones, assumes returns to be T-distributed which leads to more robust estimates than a standard linear regression would.  The default benchmark is the S&P500.  Alternatively, users may use the Fama-French model as a bunchmark by setting benchmark_rets=\"Fama-French\".  \n\n\nBy default, stoch_vol=False because running the stochastic volatility model is computationally expensive.\n\n\nOnly the most recent 400 days of returns are used when computing the stochastic volatility model.  This is to minimize computational time.\n\n\n\n\nRunning models directly\n\n\nYou can also run individual models. All models can be found in \npyfolio.bayesian\n and run via the \nrun_model()\n function.\n\n\nhelp(pf.bayesian.run_model)\n\n\n\n\nHelp on function run_model in module pyfolio.bayesian:\n\nrun_model(model, returns_train, returns_test=None, bmark=None, samples=500, ppc=False)\n    Run one of the Bayesian models.\n\n    Parameters\n    ----------\n    model : {'alpha_beta', 't', 'normal', 'best'}\n        Which model to run\n    returns_train : pd.Series\n        Timeseries of simple returns\n    returns_test : pd.Series (optional)\n        Out-of-sample returns. Datetimes in returns_test will be added to\n        returns_train as missing values and predictions will be generated\n        for them.\n    bmark : pd.Series or pd.DataFrame (optional)\n        Only used for alpha_beta to estimate regression coefficients.\n        If bmark has more recent returns than returns_train, these dates\n        will be treated as missing values and predictions will be\n        generated for them taking market correlations into account.\n    samples : int (optional)\n        Number of posterior samples to draw.\n    ppc : boolean (optional)\n        Whether to run a posterior predictive check. Will generate\n        samples of length returns_test.  Returns a second argument\n        that contains the PPC of shape samples x len(returns_test).\n\n    Returns\n    -------\n    trace : pymc3.sampling.BaseTrace object\n        A PyMC3 trace object that contains samples for each parameter\n        of the posterior.\n\n    ppc : numpy.array (if ppc==True)\n       PPC of shape samples x len(returns_test).\n\n\n\nFor example, to run a model that assumes returns to be normally distributed, you can call:\n\n\n# Run model that assumes returns to be T-distributed\ntrace = pf.bayesian.run_model('t', stock_rets)\n\n\n\n\nApplied log-transform to volatility and added transformed volatility_log to model.\nApplied log-transform to nu_minus_two and added transformed nu_minus_two_log to model.\n [-----------------100%-----------------] 500 of 500 complete in 1.9 sec\n\n\n\nThe returned trace object can be directly inquired. For example might we ask what the probability of the Sharpe ratio being larger than 0 is by checking what percentage of posterior samples of the Sharpe ratio are > 0:\n\n\n# Check what frequency of samples from the sharpe posterior are above 0.\nprint('Probability of Sharpe ratio > 0 = {:3}%'.format((trace['sharpe'] > 0).mean() * 100))\n\n\n\n\nProbability of Sharpe ratio > 0 = 92.0%\n\n\n\nBut we can also interact with it like with any other \npymc3\n trace:\n\n\nimport pymc3 as pm\npm.traceplot(trace);\n\n\n\n\n\n\nFurther reading\n\n\nFor more information on Bayesian statistics, check out these resources:\n\n\n\n\nA blog post about the Bayesian models with Sepideh Sadeghi\n\n\nMy personal blog on Bayesian modeling\n\n\nA talk I gave in Singapore on \nProbabilistic Programming in Quantitative Finance\n\n\nThe IPython NB book \nBayesian Methods for Hackers\n.",
            "title": "Bayesian analysis"
        },
        {
            "location": "/notebooks/bayesian/#bayesian-performance-analysis-example-in-pyfolio",
            "text": "There are also a few more advanced (and still experimental) analysis methods in pyfolio based on Bayesian statistics.   The main benefit of these methods is  uncertainty quantification . All the values you saw above, like the Sharpe ratio, are just single numbers. These estimates are noisy because they have been computed over a limited number of data points. So how much can you trust these numbers? You don't know because there is no sense of uncertainty. That is where Bayesian statistics helps as instead of single values, we are dealing with probability distributions that assign degrees of belief to all possible parameter values.  Lets create the Bayesian tear sheet. Under the hood this is running MCMC sampling in  PyMC3  to estimate the posteriors which can take quite a while (that's the reason why we don't generate this by default in  create_full_tear_sheet() ).",
            "title": "Bayesian performance analysis example in pyfolio"
        },
        {
            "location": "/notebooks/bayesian/#import-pyfolio",
            "text": "%matplotlib inline\nimport pyfolio as pf",
            "title": "Import pyfolio"
        },
        {
            "location": "/notebooks/bayesian/#fetch-the-daily-returns-for-a-stock",
            "text": "stock_rets = pf.utils.get_symbol_rets('FB')",
            "title": "Fetch the daily returns for a stock"
        },
        {
            "location": "/notebooks/bayesian/#create-bayesian-tear-sheet",
            "text": "out_of_sample = stock_rets.index[-40]  pf.create_bayesian_tear_sheet(stock_rets, live_start_date=out_of_sample)  Running T model\n\n\nWARNING (theano.gof.compilelock): Overriding existing lock by dead process '23486' (I am process '24728')\n\n\nApplied log-transform to volatility and added transformed volatility_log to model.\nApplied log-transform to nu_minus_two and added transformed nu_minus_two_log to model.\n [-----------------100%-----------------] 2000 of 2000 complete in 14.8 sec\nFinished T model (required 279.00 seconds).\n\nRunning BEST model\nApplied interval-transform to group1_std and added transformed group1_std_interval to model.\nApplied interval-transform to group2_std and added transformed group2_std_interval to model.\nApplied log-transform to nu_minus_two and added transformed nu_minus_two_log to model.\n [-----------------100%-----------------] 2000 of 2000 complete in 12.6 sec\nFinished BEST model (required 132.06 seconds).\n\nFinished plotting Bayesian cone (required 0.21 seconds).\n\n\n/home/wiecki/miniconda3/lib/python3.5/site-packages/matplotlib/axes/_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n  warnings.warn(\"No labelled objects found. \"\n\n\n\nFinished plotting BEST results (required 1.45 seconds).\n\nFinished computing Bayesian predictions (required 0.26 seconds).\n\nFinished plotting Bayesian VaRs estimate (required 0.12 seconds).\n\nRunning alpha beta model\nApplied log-transform to sigma and added transformed sigma_log to model.\nApplied log-transform to nu_minus_two and added transformed nu_minus_two_log to model.\n [-----------------100%-----------------] 2000 of 2000 complete in 7.2 sec\nFinished running alpha beta model (required 130.28 seconds).\n\nFinished plotting alpha beta model (required 0.24 seconds).\n\nTotal runtime was 543.62 seconds.   Lets go through these row by row:   The first one is the Bayesian cone plot that is the result of a summer internship project of Sepideh Sadeghi here at Quantopian. It's similar to the cone plot you already saw in the tear sheet above but has two critical additions: (i) it takes uncertainty into account (i.e. a short backtest length will result in a wider cone), and (ii) it does not assume normality of returns but instead uses a  Student-T distribution  with heavier tails.  The next row compares mean returns of the in-sample (backest) and out-of-sample or OOS (forward) period. As you can see, mean returns are not a single number but a (posterior) distribution that gives us an indication of how certain we can be in our estimates. The green distribution on the left side is much wider, representing our increased uncertainty due to having less OOS data. We can then calculate the difference between these two distributions as shown on the right side. The grey lines denote the 2.5% and 97.5% percentiles. Intuitively, if the right grey line is lower than 0 you can say that with probability > 97.5% the OOS mean returns are below what is suggested by the backtest. The model used here is called  BEST  and was developed by John Kruschke.  The next couple of rows follow the same pattern but are an estimate of annual volatility, Sharpe ratio and their respective differences.  The 5th row shows the effect size or the difference of means normalized by the standard deviation and gives you a general sense how far apart the two distributions are. Intuitively, even if the means are significantly different, it may not be very meaningful if the standard deviation is huge amounting to a tiny difference of the two returns distributions.  The 6th row shows predicted returns (based on the backtest) for tomorrow, and 5 days from now. The blue line indicates the probability of losing more than 5% of your portfolio value and can be interpeted as a Bayesian VaR estimate.  The 7th row shows a Bayesian estimate of annual alpha and beta. In addition to uncertainty estimates, this model, like all above ones, assumes returns to be T-distributed which leads to more robust estimates than a standard linear regression would.  The default benchmark is the S&P500.  Alternatively, users may use the Fama-French model as a bunchmark by setting benchmark_rets=\"Fama-French\".    By default, stoch_vol=False because running the stochastic volatility model is computationally expensive.  Only the most recent 400 days of returns are used when computing the stochastic volatility model.  This is to minimize computational time.",
            "title": "Create Bayesian tear sheet"
        },
        {
            "location": "/notebooks/bayesian/#running-models-directly",
            "text": "You can also run individual models. All models can be found in  pyfolio.bayesian  and run via the  run_model()  function.  help(pf.bayesian.run_model)  Help on function run_model in module pyfolio.bayesian:\n\nrun_model(model, returns_train, returns_test=None, bmark=None, samples=500, ppc=False)\n    Run one of the Bayesian models.\n\n    Parameters\n    ----------\n    model : {'alpha_beta', 't', 'normal', 'best'}\n        Which model to run\n    returns_train : pd.Series\n        Timeseries of simple returns\n    returns_test : pd.Series (optional)\n        Out-of-sample returns. Datetimes in returns_test will be added to\n        returns_train as missing values and predictions will be generated\n        for them.\n    bmark : pd.Series or pd.DataFrame (optional)\n        Only used for alpha_beta to estimate regression coefficients.\n        If bmark has more recent returns than returns_train, these dates\n        will be treated as missing values and predictions will be\n        generated for them taking market correlations into account.\n    samples : int (optional)\n        Number of posterior samples to draw.\n    ppc : boolean (optional)\n        Whether to run a posterior predictive check. Will generate\n        samples of length returns_test.  Returns a second argument\n        that contains the PPC of shape samples x len(returns_test).\n\n    Returns\n    -------\n    trace : pymc3.sampling.BaseTrace object\n        A PyMC3 trace object that contains samples for each parameter\n        of the posterior.\n\n    ppc : numpy.array (if ppc==True)\n       PPC of shape samples x len(returns_test).  For example, to run a model that assumes returns to be normally distributed, you can call:  # Run model that assumes returns to be T-distributed\ntrace = pf.bayesian.run_model('t', stock_rets)  Applied log-transform to volatility and added transformed volatility_log to model.\nApplied log-transform to nu_minus_two and added transformed nu_minus_two_log to model.\n [-----------------100%-----------------] 500 of 500 complete in 1.9 sec  The returned trace object can be directly inquired. For example might we ask what the probability of the Sharpe ratio being larger than 0 is by checking what percentage of posterior samples of the Sharpe ratio are > 0:  # Check what frequency of samples from the sharpe posterior are above 0.\nprint('Probability of Sharpe ratio > 0 = {:3}%'.format((trace['sharpe'] > 0).mean() * 100))  Probability of Sharpe ratio > 0 = 92.0%  But we can also interact with it like with any other  pymc3  trace:  import pymc3 as pm\npm.traceplot(trace);",
            "title": "Running models directly"
        },
        {
            "location": "/notebooks/bayesian/#further-reading",
            "text": "For more information on Bayesian statistics, check out these resources:   A blog post about the Bayesian models with Sepideh Sadeghi  My personal blog on Bayesian modeling  A talk I gave in Singapore on  Probabilistic Programming in Quantitative Finance  The IPython NB book  Bayesian Methods for Hackers .",
            "title": "Further reading"
        },
        {
            "location": "/notebooks/sector_mapping_example/",
            "text": "Sector Mappings\n\n\nTo generate sector allocation plots in the positions tearsheet and PnL by sector in the round trips tearsheet, you must pass pyfolio a dictionary (or dict-like data struction) of symbol-sector mappings, where symbols are keys and sectors are values. \ncreate_full_tearsheet\n will also take symbol-sector mappings as keyword argument \nsector_mappings\n.\n\n\n%matplotlib inline\nimport pyfolio as pf\nimport gzip\nimport os\nimport pandas as pd\n\n\n\n\ntransactions = pd.read_csv(gzip.open('../tests/test_data/test_txn.csv.gz'),\n                    index_col=0, parse_dates=0)\npositions = pd.read_csv(gzip.open('../tests/test_data/test_pos.csv.gz'),\n                    index_col=0, parse_dates=0)\nreturns = pd.read_csv(gzip.open('../tests/test_data/test_returns.csv.gz'),\n                    index_col=0, parse_dates=0, header=None)[1]\ngross_lev = pd.read_csv(gzip.open('../tests/test_data/test_gross_lev.csv.gz'),\n                    index_col=0, parse_dates=0, header=None)[1]\n\n\n\n\nreturns.index = returns.index.tz_localize(\"UTC\")\npositions.index = positions.index.tz_localize(\"UTC\")\ntransactions.index = transactions.index.tz_localize(\"UTC\")\ngross_lev.index = gross_lev.index.tz_localize(\"UTC\")\n\n\n\n\n\npositions.head(2)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nAMD\n\n      \nCERN\n\n      \nCOST\n\n      \nDELL\n\n      \nGPS\n\n      \nINTC\n\n      \nMMM\n\n      \ncash\n\n    \n\n    \n\n      \nindex\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2004-01-09 00:00:00+00:00\n\n      \n6961.92\n\n      \n21017.07875\n\n      \n7282.266152\n\n      \n21264.55188\n\n      \n7091.080020\n\n      \n21259.33389\n\n      \n21316.129606\n\n      \n-6192.360298\n\n    \n\n    \n\n      \n2004-01-12 00:00:00+00:00\n\n      \n18198.58\n\n      \n18071.25000\n\n      \n17675.836401\n\n      \n10804.31924\n\n      \n10685.411865\n\n      \n17872.47748\n\n      \n10882.026400\n\n      \n-3329.289887\n\n    \n\n  \n\n\n\n\n\n\n\nsect_map = {'COST': 'Consumer Goods', \n            'INTC': 'Technology', \n            'CERN': 'Healthcare', \n            'GPS': 'Technology',\n            'MMM': 'Construction', \n            'DELL': 'Technology', \n            'AMD': 'Technology'}\n\n\n\n\npf.create_position_tear_sheet(returns, positions, gross_lev=gross_lev, sector_mappings=sect_map)\n\n\n\n\n\nTop 10 long positions of all time (and max%)\n['COST' 'DELL' 'CERN' 'MMM' 'INTC' 'AMD' 'GPS']\n[ 0.9    0.857  0.835  0.821  0.786  0.758  0.622]\n\n\nTop 10 short positions of all time (and max%)\n['AMD' 'DELL' 'CERN' 'MMM' 'GPS' 'INTC' 'COST']\n[-0.301 -0.266 -0.255 -0.226 -0.201 -0.185 -0.164]\n\n\nTop 10 positions of all time (and max%)\n['COST' 'DELL' 'CERN' 'MMM' 'INTC' 'AMD' 'GPS']\n[ 0.9    0.857  0.835  0.821  0.786  0.758  0.622]\n\n\nAll positions ever held\n['COST' 'DELL' 'CERN' 'MMM' 'INTC' 'AMD' 'GPS']\n[ 0.9    0.857  0.835  0.821  0.786  0.758  0.622]\n\n\n\n\n\npf.create_round_trip_tear_sheet(positions, transactions, sector_mappings=sect_map)\n\n\n\n\n                      duration           pnl      returns      long\ncount                     1430   1430.000000  1430.000000      1430\nmean    9 days 16:40:56.154545     45.737238     0.003543  0.523077\nstd    22 days 02:16:41.165898   1616.537844     0.031288  0.499642\nmin            0 days 00:00:00 -30697.460000    -0.218045     False\n25%            0 days 23:59:59     -5.773144    -0.011450         0\n50%            2 days 23:59:59      0.871629     0.003885         1\n75%            5 days 23:59:59     40.438366     0.018126         1\nmax          286 days 00:00:00  17835.869482     0.204385      True\nPercent of round trips profitable = 57.2%\nMean return per winning round trip = 0.02181\nMean return per losing round trip = -0.02108\nA decision is made every 1.053 days.\n0.9495 trading decisions per day.\n19.94 trading decisions per month.\n\nProfitability (PnL / PnL total) per name:\nsymbol\nCOST    0.398964\nINTC    0.382659\nCERN    0.323077\nMMM     0.221479\nGPS     0.049385\nAMD    -0.064091\nDELL   -0.311473\nName: pnl, dtype: float64\n\nProfitability (PnL / PnL total) per name:\nsymbol\nConsumer Goods    0.398964\nHealthcare        0.323077\nConstruction      0.221479\nTechnology        0.056480\nName: pnl, dtype: float64\n\n\n\n<matplotlib.figure.Figure at 0x109d0f650>",
            "title": "Sector analysis"
        },
        {
            "location": "/notebooks/sector_mapping_example/#sector-mappings",
            "text": "To generate sector allocation plots in the positions tearsheet and PnL by sector in the round trips tearsheet, you must pass pyfolio a dictionary (or dict-like data struction) of symbol-sector mappings, where symbols are keys and sectors are values.  create_full_tearsheet  will also take symbol-sector mappings as keyword argument  sector_mappings .  %matplotlib inline\nimport pyfolio as pf\nimport gzip\nimport os\nimport pandas as pd  transactions = pd.read_csv(gzip.open('../tests/test_data/test_txn.csv.gz'),\n                    index_col=0, parse_dates=0)\npositions = pd.read_csv(gzip.open('../tests/test_data/test_pos.csv.gz'),\n                    index_col=0, parse_dates=0)\nreturns = pd.read_csv(gzip.open('../tests/test_data/test_returns.csv.gz'),\n                    index_col=0, parse_dates=0, header=None)[1]\ngross_lev = pd.read_csv(gzip.open('../tests/test_data/test_gross_lev.csv.gz'),\n                    index_col=0, parse_dates=0, header=None)[1]  returns.index = returns.index.tz_localize(\"UTC\")\npositions.index = positions.index.tz_localize(\"UTC\")\ntransactions.index = transactions.index.tz_localize(\"UTC\")\ngross_lev.index = gross_lev.index.tz_localize(\"UTC\")  positions.head(2)   \n   \n     \n       \n       AMD \n       CERN \n       COST \n       DELL \n       GPS \n       INTC \n       MMM \n       cash \n     \n     \n       index \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2004-01-09 00:00:00+00:00 \n       6961.92 \n       21017.07875 \n       7282.266152 \n       21264.55188 \n       7091.080020 \n       21259.33389 \n       21316.129606 \n       -6192.360298 \n     \n     \n       2004-01-12 00:00:00+00:00 \n       18198.58 \n       18071.25000 \n       17675.836401 \n       10804.31924 \n       10685.411865 \n       17872.47748 \n       10882.026400 \n       -3329.289887 \n     \n      sect_map = {'COST': 'Consumer Goods', \n            'INTC': 'Technology', \n            'CERN': 'Healthcare', \n            'GPS': 'Technology',\n            'MMM': 'Construction', \n            'DELL': 'Technology', \n            'AMD': 'Technology'}  pf.create_position_tear_sheet(returns, positions, gross_lev=gross_lev, sector_mappings=sect_map)  Top 10 long positions of all time (and max%)\n['COST' 'DELL' 'CERN' 'MMM' 'INTC' 'AMD' 'GPS']\n[ 0.9    0.857  0.835  0.821  0.786  0.758  0.622]\n\n\nTop 10 short positions of all time (and max%)\n['AMD' 'DELL' 'CERN' 'MMM' 'GPS' 'INTC' 'COST']\n[-0.301 -0.266 -0.255 -0.226 -0.201 -0.185 -0.164]\n\n\nTop 10 positions of all time (and max%)\n['COST' 'DELL' 'CERN' 'MMM' 'INTC' 'AMD' 'GPS']\n[ 0.9    0.857  0.835  0.821  0.786  0.758  0.622]\n\n\nAll positions ever held\n['COST' 'DELL' 'CERN' 'MMM' 'INTC' 'AMD' 'GPS']\n[ 0.9    0.857  0.835  0.821  0.786  0.758  0.622]   pf.create_round_trip_tear_sheet(positions, transactions, sector_mappings=sect_map)                        duration           pnl      returns      long\ncount                     1430   1430.000000  1430.000000      1430\nmean    9 days 16:40:56.154545     45.737238     0.003543  0.523077\nstd    22 days 02:16:41.165898   1616.537844     0.031288  0.499642\nmin            0 days 00:00:00 -30697.460000    -0.218045     False\n25%            0 days 23:59:59     -5.773144    -0.011450         0\n50%            2 days 23:59:59      0.871629     0.003885         1\n75%            5 days 23:59:59     40.438366     0.018126         1\nmax          286 days 00:00:00  17835.869482     0.204385      True\nPercent of round trips profitable = 57.2%\nMean return per winning round trip = 0.02181\nMean return per losing round trip = -0.02108\nA decision is made every 1.053 days.\n0.9495 trading decisions per day.\n19.94 trading decisions per month.\n\nProfitability (PnL / PnL total) per name:\nsymbol\nCOST    0.398964\nINTC    0.382659\nCERN    0.323077\nMMM     0.221479\nGPS     0.049385\nAMD    -0.064091\nDELL   -0.311473\nName: pnl, dtype: float64\n\nProfitability (PnL / PnL total) per name:\nsymbol\nConsumer Goods    0.398964\nHealthcare        0.323077\nConstruction      0.221479\nTechnology        0.056480\nName: pnl, dtype: float64\n\n\n\n<matplotlib.figure.Figure at 0x109d0f650>",
            "title": "Sector Mappings"
        },
        {
            "location": "/notebooks/round_trip_example/",
            "text": "Round Trip Tearsheet\n\n\nWhen evaluating the performance of an investing strategy, it is helpful to quantify the frequency, duration, and profitability of its independent bets, or \"round trip\" trades. A round trip trade is started when a new long or short position is opened and then later completely or partially closed out.\n\n\nThe intent of the round trip tearsheet is to help differentiate strategies that profited off a few lucky trades from strategies that profited repeatedly from genuine alpha. Breaking down round trip profitability by traded name and sector can also help inform universe selection and identify exposure risks. For example, even if your equity curve looks robust, if only two securities in your universe of fifteen names contributed to overall profitability, you may have reason to question the logic of your strategy.\n\n\nTo identify round trips, pyfolio reconstructs the complete portfolio based on the transactions that you pass in. When you make a trade, pyfolio checks if shares are already present in your portfolio purchased at a certain price. If there are, we compute the PnL, returns and duration of that round trip trade. In calculating round trips, pyfolio will also append position closing transactions at the last timestamp in the positions data. This closing transaction will cause the PnL from any open positions to realized as completed round trips.\n\n\n%matplotlib inline\nimport gzip\nimport os\nimport pandas as pd\nimport pyfolio as pf\n\n\n\n\ntransactions = pd.read_csv(gzip.open('../tests/test_data/test_txn.csv.gz'),\n                    index_col=0, parse_dates=0)\npositions = pd.read_csv(gzip.open('../tests/test_data/test_pos.csv.gz'),\n                    index_col=0, parse_dates=0)\nreturns = pd.read_csv(gzip.open('../tests/test_data/test_returns.csv.gz'),\n                      index_col=0, parse_dates=0, header=None)[1]\n\n\n\n\n# Optional: Sector mappings may be passed in as a dict or pd.Series. If a mapping is\n# provided, PnL from symbols with mappings will be summed to display profitability by sector.\nsect_map = {'COST': 'Consumer Goods', 'INTC':'Technology', 'CERN':'Healthcare', 'GPS':'Technology',\n            'MMM': 'Construction', 'DELL': 'Technology', 'AMD':'Technology'}\n\n\n\n\nThe easiest way to run the analysis is to call \npyfolio.create_round_trip_tear_sheet()\n. Passing in a sector map is optional. You can also pass \nround_trips=True\n to \npyfolio.create_full_tear_sheet()\n to have this be created along all the other analyses.\n\n\npf.create_round_trip_tear_sheet(returns, positions, transactions, sector_mappings=sect_map)\n\n\n\n\n\n\n\n  \n\n    \n\n      \nSummary stats\n\n      \nAll trades\n\n      \nLong trades\n\n      \nShort trades\n\n    \n\n  \n\n  \n\n    \n\n      \nTotal number of round_trips\n\n      \n5822.00\n\n      \n4667.00\n\n      \n1155.00\n\n    \n\n    \n\n      \nPercent profitable\n\n      \n0.50\n\n      \n0.49\n\n      \n0.52\n\n    \n\n    \n\n      \nWinning round_trips\n\n      \n2887.00\n\n      \n2291.00\n\n      \n596.00\n\n    \n\n    \n\n      \nLosing round_trips\n\n      \n2917.00\n\n      \n2364.00\n\n      \n553.00\n\n    \n\n    \n\n      \nEven round_trips\n\n      \n18.00\n\n      \n12.00\n\n      \n6.00\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nPnL stats\n\n      \nAll trades\n\n      \nLong trades\n\n      \nShort trades\n\n    \n\n  \n\n  \n\n    \n\n      \nTotal profit\n\n      \n$65404.25\n\n      \n$61844.15\n\n      \n$3560.10\n\n    \n\n    \n\n      \nGross profit\n\n      \n$448803.34\n\n      \n$428194.89\n\n      \n$20608.45\n\n    \n\n    \n\n      \nGross loss\n\n      \n$-383399.09\n\n      \n$-366350.75\n\n      \n$-17048.35\n\n    \n\n    \n\n      \nProfit factor\n\n      \n$1.17\n\n      \n$1.17\n\n      \n$1.21\n\n    \n\n    \n\n      \nAvg. trade net profit\n\n      \n$11.23\n\n      \n$13.25\n\n      \n$3.08\n\n    \n\n    \n\n      \nAvg. winning trade\n\n      \n$155.46\n\n      \n$186.90\n\n      \n$34.58\n\n    \n\n    \n\n      \nAvg. losing trade\n\n      \n$-131.44\n\n      \n$-154.97\n\n      \n$-30.83\n\n    \n\n    \n\n      \nRatio Avg. Win:Avg. Loss\n\n      \n$1.18\n\n      \n$1.21\n\n      \n$1.12\n\n    \n\n    \n\n      \nLargest winning trade\n\n      \n$9500.14\n\n      \n$9500.14\n\n      \n$1623.24\n\n    \n\n    \n\n      \nLargest losing trade\n\n      \n$-22902.83\n\n      \n$-22902.83\n\n      \n$-661.29\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nDuration stats\n\n      \nAll trades\n\n      \nLong trades\n\n      \nShort trades\n\n    \n\n  \n\n  \n\n    \n\n      \nAvg duration\n\n      \n13 days 03:21:49.653555\n\n      \n15 days 18:53:36.628026\n\n      \n2 days 10:39:35.064935\n\n    \n\n    \n\n      \nMedian duration\n\n      \n8 days 00:00:00\n\n      \n12 days 00:00:00\n\n      \n2 days 00:00:00\n\n    \n\n    \n\n      \nAvg # round_trips per day\n\n      \n70.14\n\n      \n56.23\n\n      \n96.25\n\n    \n\n    \n\n      \nAvg # round_trips per month\n\n      \n1473.04\n\n      \n1180.81\n\n      \n2021.25\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nReturn stats\n\n      \nAll trades\n\n      \nLong trades\n\n      \nShort trades\n\n    \n\n  \n\n  \n\n    \n\n      \nAvg returns all round_trips\n\n      \n0.01%\n\n      \n0.01%\n\n      \n0.00%\n\n    \n\n    \n\n      \nAvg returns winning\n\n      \n0.13%\n\n      \n0.15%\n\n      \n0.03%\n\n    \n\n    \n\n      \nAvg returns losing\n\n      \n-0.11%\n\n      \n-0.13%\n\n      \n-0.03%\n\n    \n\n    \n\n      \nMedian returns all round_trips\n\n      \n-0.00%\n\n      \n-0.00%\n\n      \n0.00%\n\n    \n\n    \n\n      \nMedian returns winning\n\n      \n0.02%\n\n      \n0.03%\n\n      \n0.01%\n\n    \n\n    \n\n      \nMedian returns losing\n\n      \n-0.01%\n\n      \n-0.02%\n\n      \n-0.00%\n\n    \n\n    \n\n      \nLargest winning trade\n\n      \n6.78%\n\n      \n6.78%\n\n      \n1.37%\n\n    \n\n    \n\n      \nLargest losing trade\n\n      \n-17.23%\n\n      \n-17.23%\n\n      \n-0.72%\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nSymbol stats\n\n      \nAMD\n\n      \nCERN\n\n      \nCOST\n\n      \nDELL\n\n      \nGPS\n\n      \nINTC\n\n      \nMMM\n\n    \n\n  \n\n  \n\n    \n\n      \nAvg returns all round_trips\n\n      \n-0.00%\n\n      \n0.02%\n\n      \n0.02%\n\n      \n-0.03%\n\n      \n0.00%\n\n      \n0.02%\n\n      \n0.01%\n\n    \n\n    \n\n      \nAvg returns winning\n\n      \n0.20%\n\n      \n0.15%\n\n      \n0.10%\n\n      \n0.11%\n\n      \n0.10%\n\n      \n0.11%\n\n      \n0.10%\n\n    \n\n    \n\n      \nAvg returns losing\n\n      \n-0.19%\n\n      \n-0.13%\n\n      \n-0.07%\n\n      \n-0.15%\n\n      \n-0.09%\n\n      \n-0.06%\n\n      \n-0.09%\n\n    \n\n    \n\n      \nMedian returns all round_trips\n\n      \n-0.00%\n\n      \n0.00%\n\n      \n0.00%\n\n      \n-0.00%\n\n      \n-0.00%\n\n      \n-0.00%\n\n      \n0.00%\n\n    \n\n    \n\n      \nMedian returns winning\n\n      \n0.03%\n\n      \n0.02%\n\n      \n0.02%\n\n      \n0.02%\n\n      \n0.02%\n\n      \n0.01%\n\n      \n0.02%\n\n    \n\n    \n\n      \nMedian returns losing\n\n      \n-0.02%\n\n      \n-0.01%\n\n      \n-0.01%\n\n      \n-0.02%\n\n      \n-0.01%\n\n      \n-0.01%\n\n      \n-0.01%\n\n    \n\n    \n\n      \nLargest winning trade\n\n      \n6.78%\n\n      \n6.14%\n\n      \n3.96%\n\n      \n2.78%\n\n      \n1.80%\n\n      \n2.40%\n\n      \n2.45%\n\n    \n\n    \n\n      \nLargest losing trade\n\n      \n-17.23%\n\n      \n-3.92%\n\n      \n-2.32%\n\n      \n-6.39%\n\n      \n-6.86%\n\n      \n-4.45%\n\n      \n-1.79%\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nProfitability (PnL / PnL total) per name\n\n      \npnl\n\n    \n\n    \n\n      \nsymbol\n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \nCOST\n\n      \n0.40%\n\n    \n\n    \n\n      \nINTC\n\n      \n0.38%\n\n    \n\n    \n\n      \nCERN\n\n      \n0.32%\n\n    \n\n    \n\n      \nMMM\n\n      \n0.22%\n\n    \n\n    \n\n      \nGPS\n\n      \n0.05%\n\n    \n\n    \n\n      \nAMD\n\n      \n-0.06%\n\n    \n\n    \n\n      \nDELL\n\n      \n-0.31%\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nProfitability (PnL / PnL total) per name\n\n      \npnl\n\n    \n\n    \n\n      \nsymbol\n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \nConsumer Goods\n\n      \n0.40%\n\n    \n\n    \n\n      \nHealthcare\n\n      \n0.32%\n\n    \n\n    \n\n      \nConstruction\n\n      \n0.22%\n\n    \n\n    \n\n      \nTechnology\n\n      \n0.06%\n\n    \n\n  \n\n\n\n\n\n\n\n<matplotlib.figure.Figure at 0x7f7281a27f28>\n\n\n\n\n\nUnder the hood, several functions are being called. \nextract_round_trips()\n does the portfolio reconstruction and creates the round-trip trades.\n\n\nrts = pf.round_trips.extract_round_trips(transactions, \n                                         portfolio_value=positions.sum(axis='columns') / (returns + 1))\n\n\n\n\nrts.head()\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nclose_dt\n\n      \nlong\n\n      \nopen_dt\n\n      \npnl\n\n      \nrt_returns\n\n      \nsymbol\n\n      \nduration\n\n      \nreturns\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \n2004-01-13\n\n      \nTrue\n\n      \n2004-01-09\n\n      \n-126.000000\n\n      \n-0.022523\n\n      \nAMD\n\n      \n4 days\n\n      \n-0.001249\n\n    \n\n    \n\n      \n1\n\n      \n2004-01-16\n\n      \nTrue\n\n      \n2004-01-09\n\n      \n50.020000\n\n      \n0.078507\n\n      \nAMD\n\n      \n7 days\n\n      \n0.000503\n\n    \n\n    \n\n      \n2\n\n      \n2004-01-20\n\n      \nTrue\n\n      \n2004-01-09\n\n      \n1540.099065\n\n      \n0.104696\n\n      \nAMD\n\n      \n11 days\n\n      \n0.015257\n\n    \n\n    \n\n      \n3\n\n      \n2004-01-21\n\n      \nFalse\n\n      \n2004-01-20\n\n      \n287.119806\n\n      \n0.085155\n\n      \nAMD\n\n      \n1 days\n\n      \n0.002861\n\n    \n\n    \n\n      \n4\n\n      \n2004-01-22\n\n      \nFalse\n\n      \n2004-01-20\n\n      \n103.349947\n\n      \n0.112198\n\n      \nAMD\n\n      \n2 days\n\n      \n0.001032\n\n    \n\n  \n\n\n\n\n\n\n\npf.round_trips.print_round_trip_stats(rts)\n\n\n\n\n\n\n\n  \n\n    \n\n      \nSummary stats\n\n      \nAll trades\n\n      \nLong trades\n\n      \nShort trades\n\n    \n\n  \n\n  \n\n    \n\n      \nTotal number of round_trips\n\n      \n5819.00\n\n      \n4664.00\n\n      \n1155.00\n\n    \n\n    \n\n      \nPercent profitable\n\n      \n0.50\n\n      \n0.49\n\n      \n0.52\n\n    \n\n    \n\n      \nWinning round_trips\n\n      \n2888.00\n\n      \n2292.00\n\n      \n596.00\n\n    \n\n    \n\n      \nLosing round_trips\n\n      \n2914.00\n\n      \n2361.00\n\n      \n553.00\n\n    \n\n    \n\n      \nEven round_trips\n\n      \n17.00\n\n      \n11.00\n\n      \n6.00\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nPnL stats\n\n      \nAll trades\n\n      \nLong trades\n\n      \nShort trades\n\n    \n\n  \n\n  \n\n    \n\n      \nTotal profit\n\n      \n$67003.94\n\n      \n$63472.61\n\n      \n$3531.32\n\n    \n\n    \n\n      \nGross profit\n\n      \n$448674.42\n\n      \n$428094.75\n\n      \n$20579.67\n\n    \n\n    \n\n      \nGross loss\n\n      \n$-381670.48\n\n      \n$-364622.13\n\n      \n$-17048.35\n\n    \n\n    \n\n      \nProfit factor\n\n      \n$1.18\n\n      \n$1.17\n\n      \n$1.21\n\n    \n\n    \n\n      \nAvg. trade net profit\n\n      \n$11.51\n\n      \n$13.61\n\n      \n$3.06\n\n    \n\n    \n\n      \nAvg. winning trade\n\n      \n$155.36\n\n      \n$186.78\n\n      \n$34.53\n\n    \n\n    \n\n      \nAvg. losing trade\n\n      \n$-130.98\n\n      \n$-154.44\n\n      \n$-30.83\n\n    \n\n    \n\n      \nRatio Avg. Win:Avg. Loss\n\n      \n$1.19\n\n      \n$1.21\n\n      \n$1.12\n\n    \n\n    \n\n      \nLargest winning trade\n\n      \n$9500.14\n\n      \n$9500.14\n\n      \n$1623.24\n\n    \n\n    \n\n      \nLargest losing trade\n\n      \n$-22902.83\n\n      \n$-22902.83\n\n      \n$-661.29\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nDuration stats\n\n      \nAll trades\n\n      \nLong trades\n\n      \nShort trades\n\n    \n\n  \n\n  \n\n    \n\n      \nAvg duration\n\n      \n13 days 03:27:07.702354\n\n      \n15 days 19:02:40.548885\n\n      \n2 days 10:39:35.064935\n\n    \n\n    \n\n      \nMedian duration\n\n      \n8 days 00:00:00\n\n      \n12 days 00:00:00\n\n      \n2 days 00:00:00\n\n    \n\n    \n\n      \nAvg # round_trips per day\n\n      \n70.11\n\n      \n56.19\n\n      \n96.25\n\n    \n\n    \n\n      \nAvg # round_trips per month\n\n      \n1472.28\n\n      \n1180.05\n\n      \n2021.25\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nReturn stats\n\n      \nAll trades\n\n      \nLong trades\n\n      \nShort trades\n\n    \n\n  \n\n  \n\n    \n\n      \nAvg returns all round_trips\n\n      \n0.01%\n\n      \n0.01%\n\n      \n0.00%\n\n    \n\n    \n\n      \nAvg returns winning\n\n      \n0.13%\n\n      \n0.15%\n\n      \n0.03%\n\n    \n\n    \n\n      \nAvg returns losing\n\n      \n-0.11%\n\n      \n-0.13%\n\n      \n-0.03%\n\n    \n\n    \n\n      \nMedian returns all round_trips\n\n      \n-0.00%\n\n      \n-0.00%\n\n      \n0.00%\n\n    \n\n    \n\n      \nMedian returns winning\n\n      \n0.02%\n\n      \n0.03%\n\n      \n0.01%\n\n    \n\n    \n\n      \nMedian returns losing\n\n      \n-0.01%\n\n      \n-0.02%\n\n      \n-0.00%\n\n    \n\n    \n\n      \nLargest winning trade\n\n      \n6.78%\n\n      \n6.78%\n\n      \n1.37%\n\n    \n\n    \n\n      \nLargest losing trade\n\n      \n-17.23%\n\n      \n-17.23%\n\n      \n-0.72%\n\n    \n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nSymbol stats\n\n      \nAMD\n\n      \nCERN\n\n      \nCOST\n\n      \nDELL\n\n      \nGPS\n\n      \nINTC\n\n      \nMMM\n\n    \n\n  \n\n  \n\n    \n\n      \nAvg returns all round_trips\n\n      \n-0.00%\n\n      \n0.02%\n\n      \n0.02%\n\n      \n-0.03%\n\n      \n0.00%\n\n      \n0.02%\n\n      \n0.01%\n\n    \n\n    \n\n      \nAvg returns winning\n\n      \n0.20%\n\n      \n0.15%\n\n      \n0.10%\n\n      \n0.11%\n\n      \n0.10%\n\n      \n0.11%\n\n      \n0.10%\n\n    \n\n    \n\n      \nAvg returns losing\n\n      \n-0.19%\n\n      \n-0.13%\n\n      \n-0.07%\n\n      \n-0.15%\n\n      \n-0.09%\n\n      \n-0.06%\n\n      \n-0.09%\n\n    \n\n    \n\n      \nMedian returns all round_trips\n\n      \n-0.00%\n\n      \n0.00%\n\n      \n0.00%\n\n      \n-0.00%\n\n      \n-0.00%\n\n      \n-0.00%\n\n      \n0.00%\n\n    \n\n    \n\n      \nMedian returns winning\n\n      \n0.03%\n\n      \n0.02%\n\n      \n0.02%\n\n      \n0.02%\n\n      \n0.02%\n\n      \n0.01%\n\n      \n0.02%\n\n    \n\n    \n\n      \nMedian returns losing\n\n      \n-0.02%\n\n      \n-0.01%\n\n      \n-0.01%\n\n      \n-0.02%\n\n      \n-0.01%\n\n      \n-0.01%\n\n      \n-0.01%\n\n    \n\n    \n\n      \nLargest winning trade\n\n      \n6.78%\n\n      \n6.14%\n\n      \n3.96%\n\n      \n2.78%\n\n      \n1.80%\n\n      \n2.40%\n\n      \n2.45%\n\n    \n\n    \n\n      \nLargest losing trade\n\n      \n-17.23%\n\n      \n-3.92%\n\n      \n-2.32%\n\n      \n-6.39%\n\n      \n-6.86%\n\n      \n-4.45%\n\n      \n-1.79%",
            "title": "Round trip analysis"
        },
        {
            "location": "/notebooks/round_trip_example/#round-trip-tearsheet",
            "text": "When evaluating the performance of an investing strategy, it is helpful to quantify the frequency, duration, and profitability of its independent bets, or \"round trip\" trades. A round trip trade is started when a new long or short position is opened and then later completely or partially closed out.  The intent of the round trip tearsheet is to help differentiate strategies that profited off a few lucky trades from strategies that profited repeatedly from genuine alpha. Breaking down round trip profitability by traded name and sector can also help inform universe selection and identify exposure risks. For example, even if your equity curve looks robust, if only two securities in your universe of fifteen names contributed to overall profitability, you may have reason to question the logic of your strategy.  To identify round trips, pyfolio reconstructs the complete portfolio based on the transactions that you pass in. When you make a trade, pyfolio checks if shares are already present in your portfolio purchased at a certain price. If there are, we compute the PnL, returns and duration of that round trip trade. In calculating round trips, pyfolio will also append position closing transactions at the last timestamp in the positions data. This closing transaction will cause the PnL from any open positions to realized as completed round trips.  %matplotlib inline\nimport gzip\nimport os\nimport pandas as pd\nimport pyfolio as pf  transactions = pd.read_csv(gzip.open('../tests/test_data/test_txn.csv.gz'),\n                    index_col=0, parse_dates=0)\npositions = pd.read_csv(gzip.open('../tests/test_data/test_pos.csv.gz'),\n                    index_col=0, parse_dates=0)\nreturns = pd.read_csv(gzip.open('../tests/test_data/test_returns.csv.gz'),\n                      index_col=0, parse_dates=0, header=None)[1]  # Optional: Sector mappings may be passed in as a dict or pd.Series. If a mapping is\n# provided, PnL from symbols with mappings will be summed to display profitability by sector.\nsect_map = {'COST': 'Consumer Goods', 'INTC':'Technology', 'CERN':'Healthcare', 'GPS':'Technology',\n            'MMM': 'Construction', 'DELL': 'Technology', 'AMD':'Technology'}  The easiest way to run the analysis is to call  pyfolio.create_round_trip_tear_sheet() . Passing in a sector map is optional. You can also pass  round_trips=True  to  pyfolio.create_full_tear_sheet()  to have this be created along all the other analyses.  pf.create_round_trip_tear_sheet(returns, positions, transactions, sector_mappings=sect_map)   \n   \n     \n       Summary stats \n       All trades \n       Long trades \n       Short trades \n     \n   \n   \n     \n       Total number of round_trips \n       5822.00 \n       4667.00 \n       1155.00 \n     \n     \n       Percent profitable \n       0.50 \n       0.49 \n       0.52 \n     \n     \n       Winning round_trips \n       2887.00 \n       2291.00 \n       596.00 \n     \n     \n       Losing round_trips \n       2917.00 \n       2364.00 \n       553.00 \n     \n     \n       Even round_trips \n       18.00 \n       12.00 \n       6.00 \n     \n       \n   \n     \n       PnL stats \n       All trades \n       Long trades \n       Short trades \n     \n   \n   \n     \n       Total profit \n       $65404.25 \n       $61844.15 \n       $3560.10 \n     \n     \n       Gross profit \n       $448803.34 \n       $428194.89 \n       $20608.45 \n     \n     \n       Gross loss \n       $-383399.09 \n       $-366350.75 \n       $-17048.35 \n     \n     \n       Profit factor \n       $1.17 \n       $1.17 \n       $1.21 \n     \n     \n       Avg. trade net profit \n       $11.23 \n       $13.25 \n       $3.08 \n     \n     \n       Avg. winning trade \n       $155.46 \n       $186.90 \n       $34.58 \n     \n     \n       Avg. losing trade \n       $-131.44 \n       $-154.97 \n       $-30.83 \n     \n     \n       Ratio Avg. Win:Avg. Loss \n       $1.18 \n       $1.21 \n       $1.12 \n     \n     \n       Largest winning trade \n       $9500.14 \n       $9500.14 \n       $1623.24 \n     \n     \n       Largest losing trade \n       $-22902.83 \n       $-22902.83 \n       $-661.29 \n     \n       \n   \n     \n       Duration stats \n       All trades \n       Long trades \n       Short trades \n     \n   \n   \n     \n       Avg duration \n       13 days 03:21:49.653555 \n       15 days 18:53:36.628026 \n       2 days 10:39:35.064935 \n     \n     \n       Median duration \n       8 days 00:00:00 \n       12 days 00:00:00 \n       2 days 00:00:00 \n     \n     \n       Avg # round_trips per day \n       70.14 \n       56.23 \n       96.25 \n     \n     \n       Avg # round_trips per month \n       1473.04 \n       1180.81 \n       2021.25 \n     \n       \n   \n     \n       Return stats \n       All trades \n       Long trades \n       Short trades \n     \n   \n   \n     \n       Avg returns all round_trips \n       0.01% \n       0.01% \n       0.00% \n     \n     \n       Avg returns winning \n       0.13% \n       0.15% \n       0.03% \n     \n     \n       Avg returns losing \n       -0.11% \n       -0.13% \n       -0.03% \n     \n     \n       Median returns all round_trips \n       -0.00% \n       -0.00% \n       0.00% \n     \n     \n       Median returns winning \n       0.02% \n       0.03% \n       0.01% \n     \n     \n       Median returns losing \n       -0.01% \n       -0.02% \n       -0.00% \n     \n     \n       Largest winning trade \n       6.78% \n       6.78% \n       1.37% \n     \n     \n       Largest losing trade \n       -17.23% \n       -17.23% \n       -0.72% \n     \n       \n   \n     \n       Symbol stats \n       AMD \n       CERN \n       COST \n       DELL \n       GPS \n       INTC \n       MMM \n     \n   \n   \n     \n       Avg returns all round_trips \n       -0.00% \n       0.02% \n       0.02% \n       -0.03% \n       0.00% \n       0.02% \n       0.01% \n     \n     \n       Avg returns winning \n       0.20% \n       0.15% \n       0.10% \n       0.11% \n       0.10% \n       0.11% \n       0.10% \n     \n     \n       Avg returns losing \n       -0.19% \n       -0.13% \n       -0.07% \n       -0.15% \n       -0.09% \n       -0.06% \n       -0.09% \n     \n     \n       Median returns all round_trips \n       -0.00% \n       0.00% \n       0.00% \n       -0.00% \n       -0.00% \n       -0.00% \n       0.00% \n     \n     \n       Median returns winning \n       0.03% \n       0.02% \n       0.02% \n       0.02% \n       0.02% \n       0.01% \n       0.02% \n     \n     \n       Median returns losing \n       -0.02% \n       -0.01% \n       -0.01% \n       -0.02% \n       -0.01% \n       -0.01% \n       -0.01% \n     \n     \n       Largest winning trade \n       6.78% \n       6.14% \n       3.96% \n       2.78% \n       1.80% \n       2.40% \n       2.45% \n     \n     \n       Largest losing trade \n       -17.23% \n       -3.92% \n       -2.32% \n       -6.39% \n       -6.86% \n       -4.45% \n       -1.79% \n     \n       \n   \n     \n       Profitability (PnL / PnL total) per name \n       pnl \n     \n     \n       symbol \n       \n     \n   \n   \n     \n       COST \n       0.40% \n     \n     \n       INTC \n       0.38% \n     \n     \n       CERN \n       0.32% \n     \n     \n       MMM \n       0.22% \n     \n     \n       GPS \n       0.05% \n     \n     \n       AMD \n       -0.06% \n     \n     \n       DELL \n       -0.31% \n     \n       \n   \n     \n       Profitability (PnL / PnL total) per name \n       pnl \n     \n     \n       symbol \n       \n     \n   \n   \n     \n       Consumer Goods \n       0.40% \n     \n     \n       Healthcare \n       0.32% \n     \n     \n       Construction \n       0.22% \n     \n     \n       Technology \n       0.06% \n     \n      <matplotlib.figure.Figure at 0x7f7281a27f28>   Under the hood, several functions are being called.  extract_round_trips()  does the portfolio reconstruction and creates the round-trip trades.  rts = pf.round_trips.extract_round_trips(transactions, \n                                         portfolio_value=positions.sum(axis='columns') / (returns + 1))  rts.head()   \n   \n     \n       \n       close_dt \n       long \n       open_dt \n       pnl \n       rt_returns \n       symbol \n       duration \n       returns \n     \n   \n   \n     \n       0 \n       2004-01-13 \n       True \n       2004-01-09 \n       -126.000000 \n       -0.022523 \n       AMD \n       4 days \n       -0.001249 \n     \n     \n       1 \n       2004-01-16 \n       True \n       2004-01-09 \n       50.020000 \n       0.078507 \n       AMD \n       7 days \n       0.000503 \n     \n     \n       2 \n       2004-01-20 \n       True \n       2004-01-09 \n       1540.099065 \n       0.104696 \n       AMD \n       11 days \n       0.015257 \n     \n     \n       3 \n       2004-01-21 \n       False \n       2004-01-20 \n       287.119806 \n       0.085155 \n       AMD \n       1 days \n       0.002861 \n     \n     \n       4 \n       2004-01-22 \n       False \n       2004-01-20 \n       103.349947 \n       0.112198 \n       AMD \n       2 days \n       0.001032 \n     \n      pf.round_trips.print_round_trip_stats(rts)   \n   \n     \n       Summary stats \n       All trades \n       Long trades \n       Short trades \n     \n   \n   \n     \n       Total number of round_trips \n       5819.00 \n       4664.00 \n       1155.00 \n     \n     \n       Percent profitable \n       0.50 \n       0.49 \n       0.52 \n     \n     \n       Winning round_trips \n       2888.00 \n       2292.00 \n       596.00 \n     \n     \n       Losing round_trips \n       2914.00 \n       2361.00 \n       553.00 \n     \n     \n       Even round_trips \n       17.00 \n       11.00 \n       6.00 \n     \n       \n   \n     \n       PnL stats \n       All trades \n       Long trades \n       Short trades \n     \n   \n   \n     \n       Total profit \n       $67003.94 \n       $63472.61 \n       $3531.32 \n     \n     \n       Gross profit \n       $448674.42 \n       $428094.75 \n       $20579.67 \n     \n     \n       Gross loss \n       $-381670.48 \n       $-364622.13 \n       $-17048.35 \n     \n     \n       Profit factor \n       $1.18 \n       $1.17 \n       $1.21 \n     \n     \n       Avg. trade net profit \n       $11.51 \n       $13.61 \n       $3.06 \n     \n     \n       Avg. winning trade \n       $155.36 \n       $186.78 \n       $34.53 \n     \n     \n       Avg. losing trade \n       $-130.98 \n       $-154.44 \n       $-30.83 \n     \n     \n       Ratio Avg. Win:Avg. Loss \n       $1.19 \n       $1.21 \n       $1.12 \n     \n     \n       Largest winning trade \n       $9500.14 \n       $9500.14 \n       $1623.24 \n     \n     \n       Largest losing trade \n       $-22902.83 \n       $-22902.83 \n       $-661.29 \n     \n       \n   \n     \n       Duration stats \n       All trades \n       Long trades \n       Short trades \n     \n   \n   \n     \n       Avg duration \n       13 days 03:27:07.702354 \n       15 days 19:02:40.548885 \n       2 days 10:39:35.064935 \n     \n     \n       Median duration \n       8 days 00:00:00 \n       12 days 00:00:00 \n       2 days 00:00:00 \n     \n     \n       Avg # round_trips per day \n       70.11 \n       56.19 \n       96.25 \n     \n     \n       Avg # round_trips per month \n       1472.28 \n       1180.05 \n       2021.25 \n     \n       \n   \n     \n       Return stats \n       All trades \n       Long trades \n       Short trades \n     \n   \n   \n     \n       Avg returns all round_trips \n       0.01% \n       0.01% \n       0.00% \n     \n     \n       Avg returns winning \n       0.13% \n       0.15% \n       0.03% \n     \n     \n       Avg returns losing \n       -0.11% \n       -0.13% \n       -0.03% \n     \n     \n       Median returns all round_trips \n       -0.00% \n       -0.00% \n       0.00% \n     \n     \n       Median returns winning \n       0.02% \n       0.03% \n       0.01% \n     \n     \n       Median returns losing \n       -0.01% \n       -0.02% \n       -0.00% \n     \n     \n       Largest winning trade \n       6.78% \n       6.78% \n       1.37% \n     \n     \n       Largest losing trade \n       -17.23% \n       -17.23% \n       -0.72% \n     \n       \n   \n     \n       Symbol stats \n       AMD \n       CERN \n       COST \n       DELL \n       GPS \n       INTC \n       MMM \n     \n   \n   \n     \n       Avg returns all round_trips \n       -0.00% \n       0.02% \n       0.02% \n       -0.03% \n       0.00% \n       0.02% \n       0.01% \n     \n     \n       Avg returns winning \n       0.20% \n       0.15% \n       0.10% \n       0.11% \n       0.10% \n       0.11% \n       0.10% \n     \n     \n       Avg returns losing \n       -0.19% \n       -0.13% \n       -0.07% \n       -0.15% \n       -0.09% \n       -0.06% \n       -0.09% \n     \n     \n       Median returns all round_trips \n       -0.00% \n       0.00% \n       0.00% \n       -0.00% \n       -0.00% \n       -0.00% \n       0.00% \n     \n     \n       Median returns winning \n       0.03% \n       0.02% \n       0.02% \n       0.02% \n       0.02% \n       0.01% \n       0.02% \n     \n     \n       Median returns losing \n       -0.02% \n       -0.01% \n       -0.01% \n       -0.02% \n       -0.01% \n       -0.01% \n       -0.01% \n     \n     \n       Largest winning trade \n       6.78% \n       6.14% \n       3.96% \n       2.78% \n       1.80% \n       2.40% \n       2.45% \n     \n     \n       Largest losing trade \n       -17.23% \n       -3.92% \n       -2.32% \n       -6.39% \n       -6.86% \n       -4.45% \n       -1.79%",
            "title": "Round Trip Tearsheet"
        },
        {
            "location": "/notebooks/slippage_example/",
            "text": "Slippage Analysis\n\n\nWhen evaluating a strategy using backtest results, we often want to know how sensitive it's performance is to implementation shortfall or slippage. pyfolio's transactions tear sheet can create \"slippage sweep\" plots that display strategy performance under various slippage assumptions. \n\n\nAdditional per-dollar slippage can be applied to returns before running a tear sheet by providing \ncreate_full_tearsheet\n with the a level of slippage in basis points (1% == 100 basis points) as the \nslippage\n keyword argument. The slippage plots in the transactions tear sheet will display returns with slippage added to the \nunadjusted\n returns. \n\n\nFor example, if you run a backtest with no transaction costs and call \ncreate_full_tearsheet(returns, positions, transactions, slippage=5)\n, 5 bps of slippage will be applied to \nreturns\n before all plots and figures, with the exception of the slippage sweep plots, are generated.\n\n\nIt is important to emphasize that the slippage plots will display performance under \nadditional\n slippage. If the passed performance data already has slippage applied, the 5 bps slippage equity curve will represent performance under 5 bps of slippage in addition to the already simulated slippage penalty. If slippage is already applied to the performance results, pass \nslippage=0\n to the \ncreate_full_tearsheet\n to trigger the creation of the additional slippage sweep plots without applying any additional slippage to the returns time series used throughout the rest of the tear sheet.\n\n\n%matplotlib inline\nimport pyfolio as pf\nimport gzip\nimport pandas as pd\n\n\n\n\ntransactions = pd.read_csv(gzip.open('../tests/test_data/test_txn.csv.gz'),\n                    index_col=0, parse_dates=0)\npositions = pd.read_csv(gzip.open('../tests/test_data/test_pos.csv.gz'),\n                    index_col=0, parse_dates=0)\nreturns = pd.read_csv(gzip.open('../tests/test_data/test_returns.csv.gz'),\n                    index_col=0, parse_dates=0, header=None)[1]\ngross_lev = pd.read_csv(gzip.open('../tests/test_data/test_gross_lev.csv.gz'),\n                    index_col=0, parse_dates=0, header=None)[1]\nreturns.index = returns.index.tz_localize(\"UTC\")\npositions.index = positions.index.tz_localize(\"UTC\")\ntransactions.index = transactions.index.tz_localize(\"UTC\")\ngross_lev.index = gross_lev.index.tz_localize(\"UTC\")\n\n\n\n\npf.create_full_tear_sheet(returns, positions, transactions, gross_lev=gross_lev, slippage=0)\n\n\n\n\nEntire data start date: 2004-01-09\nEntire data end date: 2009-12-31\n\n\nBacktest Months: 71\n\n\n\n\n  \n\n    \n\n      \nPerformance statistics\n\n      \nBacktest\n\n    \n\n  \n\n  \n\n    \n\n      \nannual_return\n\n      \n0.09\n\n    \n\n    \n\n      \nannual_volatility\n\n      \n0.26\n\n    \n\n    \n\n      \nsharpe_ratio\n\n      \n0.45\n\n    \n\n    \n\n      \ncalmar_ratio\n\n      \n0.15\n\n    \n\n    \n\n      \nstability_of_timeseries\n\n      \n-0.04\n\n    \n\n    \n\n      \nmax_drawdown\n\n      \n-0.60\n\n    \n\n    \n\n      \nomega_ratio\n\n      \n1.09\n\n    \n\n    \n\n      \nsortino_ratio\n\n      \n0.66\n\n    \n\n    \n\n      \nskew\n\n      \n0.14\n\n    \n\n    \n\n      \nkurtosis\n\n      \n5.88\n\n    \n\n    \n\n      \ntail_ratio\n\n      \n0.99\n\n    \n\n    \n\n      \ncommon_sense_ratio\n\n      \n1.08\n\n    \n\n    \n\n      \ninformation_ratio\n\n      \n0.03\n\n    \n\n    \n\n      \nalpha\n\n      \n0.08\n\n    \n\n    \n\n      \nbeta\n\n      \n0.83\n\n    \n\n  \n\n\n\n\n\n\n  \n\n    \n\n      \nWorst Drawdown Periods\n\n      \nnet drawdown in %\n\n      \npeak date\n\n      \nvalley date\n\n      \nrecovery date\n\n      \nduration\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \n60.39\n\n      \n2007-11-06\n\n      \n2009-03-09\n\n      \nNaT\n\n      \nNaN\n\n    \n\n    \n\n      \n1\n\n      \n24.10\n\n      \n2005-07-28\n\n      \n2006-09-07\n\n      \n2007-05-22\n\n      \n474\n\n    \n\n    \n\n      \n4\n\n      \n11.89\n\n      \n2004-06-25\n\n      \n2004-08-12\n\n      \n2004-11-05\n\n      \n96\n\n    \n\n    \n\n      \n2\n\n      \n10.87\n\n      \n2004-11-15\n\n      \n2005-04-18\n\n      \n2005-07-14\n\n      \n174\n\n    \n\n    \n\n      \n3\n\n      \n9.51\n\n      \n2007-07-16\n\n      \n2007-08-06\n\n      \n2007-09-13\n\n      \n44\n\n    \n\n  \n\n\n\n\n\n[-0.033 -0.072]\n\n\n\n\n\n\n  \n\n    \n\n      \nStress Events\n\n      \nmean\n\n      \nmin\n\n      \nmax\n\n    \n\n  \n\n  \n\n    \n\n      \nLehmann\n\n      \n-0.27%\n\n      \n-4.70%\n\n      \n4.11%\n\n    \n\n    \n\n      \nAug07\n\n      \n0.32%\n\n      \n-2.96%\n\n      \n2.92%\n\n    \n\n    \n\n      \nMar08\n\n      \n-0.43%\n\n      \n-3.26%\n\n      \n3.36%\n\n    \n\n    \n\n      \nSept08\n\n      \n-0.68%\n\n      \n-4.38%\n\n      \n4.08%\n\n    \n\n    \n\n      \n2009Q1\n\n      \n-0.36%\n\n      \n-5.02%\n\n      \n3.39%\n\n    \n\n    \n\n      \n2009Q2\n\n      \n0.74%\n\n      \n-4.03%\n\n      \n6.13%\n\n    \n\n    \n\n      \nLow Volatility Bull Market\n\n      \n0.01%\n\n      \n-6.07%\n\n      \n6.43%\n\n    \n\n    \n\n      \nGFC Crash\n\n      \n-0.09%\n\n      \n-11.76%\n\n      \n10.13%\n\n    \n\n    \n\n      \nRecovery\n\n      \n0.35%\n\n      \n-4.03%\n\n      \n6.01%\n\n    \n\n  \n\n\n\n\n\n\n\n\n  \n\n    \n\n      \nTop 10 long positions of all time\n\n      \nmax\n\n    \n\n  \n\n  \n\n    \n\n      \nCOST\n\n      \n90.01%\n\n    \n\n    \n\n      \nDELL\n\n      \n85.73%\n\n    \n\n    \n\n      \nCERN\n\n      \n83.53%\n\n    \n\n    \n\n      \nMMM\n\n      \n82.09%\n\n    \n\n    \n\n      \nINTC\n\n      \n78.59%\n\n    \n\n    \n\n      \nAMD\n\n      \n75.76%\n\n    \n\n    \n\n      \nGPS\n\n      \n62.24%\n\n    \n\n  \n\n\n\n\n\n\n  \n\n    \n\n      \nTop 10 short positions of all time\n\n      \nmax\n\n    \n\n  \n\n  \n\n    \n\n      \nAMD\n\n      \n-30.12%\n\n    \n\n    \n\n      \nDELL\n\n      \n-26.58%\n\n    \n\n    \n\n      \nCERN\n\n      \n-25.51%\n\n    \n\n    \n\n      \nMMM\n\n      \n-22.62%\n\n    \n\n    \n\n      \nGPS\n\n      \n-20.09%\n\n    \n\n    \n\n      \nINTC\n\n      \n-18.47%\n\n    \n\n    \n\n      \nCOST\n\n      \n-16.44%\n\n    \n\n  \n\n\n\n\n\n\n  \n\n    \n\n      \nTop 10 positions of all time\n\n      \nmax\n\n    \n\n  \n\n  \n\n    \n\n      \nCOST\n\n      \n90.01%\n\n    \n\n    \n\n      \nDELL\n\n      \n85.73%\n\n    \n\n    \n\n      \nCERN\n\n      \n83.53%\n\n    \n\n    \n\n      \nMMM\n\n      \n82.09%\n\n    \n\n    \n\n      \nINTC\n\n      \n78.59%\n\n    \n\n    \n\n      \nAMD\n\n      \n75.76%\n\n    \n\n    \n\n      \nGPS\n\n      \n62.24%\n\n    \n\n  \n\n\n\n\n\n\n  \n\n    \n\n      \nAll positions ever held\n\n      \nmax\n\n    \n\n  \n\n  \n\n    \n\n      \nCOST\n\n      \n90.01%\n\n    \n\n    \n\n      \nDELL\n\n      \n85.73%\n\n    \n\n    \n\n      \nCERN\n\n      \n83.53%\n\n    \n\n    \n\n      \nMMM\n\n      \n82.09%\n\n    \n\n    \n\n      \nINTC\n\n      \n78.59%\n\n    \n\n    \n\n      \nAMD\n\n      \n75.76%\n\n    \n\n    \n\n      \nGPS\n\n      \n62.24%",
            "title": "Slippage analysis"
        },
        {
            "location": "/notebooks/slippage_example/#slippage-analysis",
            "text": "When evaluating a strategy using backtest results, we often want to know how sensitive it's performance is to implementation shortfall or slippage. pyfolio's transactions tear sheet can create \"slippage sweep\" plots that display strategy performance under various slippage assumptions.   Additional per-dollar slippage can be applied to returns before running a tear sheet by providing  create_full_tearsheet  with the a level of slippage in basis points (1% == 100 basis points) as the  slippage  keyword argument. The slippage plots in the transactions tear sheet will display returns with slippage added to the  unadjusted  returns.   For example, if you run a backtest with no transaction costs and call  create_full_tearsheet(returns, positions, transactions, slippage=5) , 5 bps of slippage will be applied to  returns  before all plots and figures, with the exception of the slippage sweep plots, are generated.  It is important to emphasize that the slippage plots will display performance under  additional  slippage. If the passed performance data already has slippage applied, the 5 bps slippage equity curve will represent performance under 5 bps of slippage in addition to the already simulated slippage penalty. If slippage is already applied to the performance results, pass  slippage=0  to the  create_full_tearsheet  to trigger the creation of the additional slippage sweep plots without applying any additional slippage to the returns time series used throughout the rest of the tear sheet.  %matplotlib inline\nimport pyfolio as pf\nimport gzip\nimport pandas as pd  transactions = pd.read_csv(gzip.open('../tests/test_data/test_txn.csv.gz'),\n                    index_col=0, parse_dates=0)\npositions = pd.read_csv(gzip.open('../tests/test_data/test_pos.csv.gz'),\n                    index_col=0, parse_dates=0)\nreturns = pd.read_csv(gzip.open('../tests/test_data/test_returns.csv.gz'),\n                    index_col=0, parse_dates=0, header=None)[1]\ngross_lev = pd.read_csv(gzip.open('../tests/test_data/test_gross_lev.csv.gz'),\n                    index_col=0, parse_dates=0, header=None)[1]\nreturns.index = returns.index.tz_localize(\"UTC\")\npositions.index = positions.index.tz_localize(\"UTC\")\ntransactions.index = transactions.index.tz_localize(\"UTC\")\ngross_lev.index = gross_lev.index.tz_localize(\"UTC\")  pf.create_full_tear_sheet(returns, positions, transactions, gross_lev=gross_lev, slippage=0)  Entire data start date: 2004-01-09\nEntire data end date: 2009-12-31\n\n\nBacktest Months: 71  \n   \n     \n       Performance statistics \n       Backtest \n     \n   \n   \n     \n       annual_return \n       0.09 \n     \n     \n       annual_volatility \n       0.26 \n     \n     \n       sharpe_ratio \n       0.45 \n     \n     \n       calmar_ratio \n       0.15 \n     \n     \n       stability_of_timeseries \n       -0.04 \n     \n     \n       max_drawdown \n       -0.60 \n     \n     \n       omega_ratio \n       1.09 \n     \n     \n       sortino_ratio \n       0.66 \n     \n     \n       skew \n       0.14 \n     \n     \n       kurtosis \n       5.88 \n     \n     \n       tail_ratio \n       0.99 \n     \n     \n       common_sense_ratio \n       1.08 \n     \n     \n       information_ratio \n       0.03 \n     \n     \n       alpha \n       0.08 \n     \n     \n       beta \n       0.83 \n     \n     \n   \n     \n       Worst Drawdown Periods \n       net drawdown in % \n       peak date \n       valley date \n       recovery date \n       duration \n     \n   \n   \n     \n       0 \n       60.39 \n       2007-11-06 \n       2009-03-09 \n       NaT \n       NaN \n     \n     \n       1 \n       24.10 \n       2005-07-28 \n       2006-09-07 \n       2007-05-22 \n       474 \n     \n     \n       4 \n       11.89 \n       2004-06-25 \n       2004-08-12 \n       2004-11-05 \n       96 \n     \n     \n       2 \n       10.87 \n       2004-11-15 \n       2005-04-18 \n       2005-07-14 \n       174 \n     \n     \n       3 \n       9.51 \n       2007-07-16 \n       2007-08-06 \n       2007-09-13 \n       44 \n     \n     [-0.033 -0.072]   \n   \n     \n       Stress Events \n       mean \n       min \n       max \n     \n   \n   \n     \n       Lehmann \n       -0.27% \n       -4.70% \n       4.11% \n     \n     \n       Aug07 \n       0.32% \n       -2.96% \n       2.92% \n     \n     \n       Mar08 \n       -0.43% \n       -3.26% \n       3.36% \n     \n     \n       Sept08 \n       -0.68% \n       -4.38% \n       4.08% \n     \n     \n       2009Q1 \n       -0.36% \n       -5.02% \n       3.39% \n     \n     \n       2009Q2 \n       0.74% \n       -4.03% \n       6.13% \n     \n     \n       Low Volatility Bull Market \n       0.01% \n       -6.07% \n       6.43% \n     \n     \n       GFC Crash \n       -0.09% \n       -11.76% \n       10.13% \n     \n     \n       Recovery \n       0.35% \n       -4.03% \n       6.01% \n     \n      \n   \n     \n       Top 10 long positions of all time \n       max \n     \n   \n   \n     \n       COST \n       90.01% \n     \n     \n       DELL \n       85.73% \n     \n     \n       CERN \n       83.53% \n     \n     \n       MMM \n       82.09% \n     \n     \n       INTC \n       78.59% \n     \n     \n       AMD \n       75.76% \n     \n     \n       GPS \n       62.24% \n     \n     \n   \n     \n       Top 10 short positions of all time \n       max \n     \n   \n   \n     \n       AMD \n       -30.12% \n     \n     \n       DELL \n       -26.58% \n     \n     \n       CERN \n       -25.51% \n     \n     \n       MMM \n       -22.62% \n     \n     \n       GPS \n       -20.09% \n     \n     \n       INTC \n       -18.47% \n     \n     \n       COST \n       -16.44% \n     \n     \n   \n     \n       Top 10 positions of all time \n       max \n     \n   \n   \n     \n       COST \n       90.01% \n     \n     \n       DELL \n       85.73% \n     \n     \n       CERN \n       83.53% \n     \n     \n       MMM \n       82.09% \n     \n     \n       INTC \n       78.59% \n     \n     \n       AMD \n       75.76% \n     \n     \n       GPS \n       62.24% \n     \n     \n   \n     \n       All positions ever held \n       max \n     \n   \n   \n     \n       COST \n       90.01% \n     \n     \n       DELL \n       85.73% \n     \n     \n       CERN \n       83.53% \n     \n     \n       MMM \n       82.09% \n     \n     \n       INTC \n       78.59% \n     \n     \n       AMD \n       75.76% \n     \n     \n       GPS \n       62.24%",
            "title": "Slippage Analysis"
        }
    ]
}